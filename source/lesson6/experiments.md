# 实验与性能分析

## 实验设置

### 数据集

我们使用以下标准数据集评估注意力机制的性能：

1. **ImageNet-1K**：包含128万训练图像和5万验证图像，1000个类别。这是评估分类性能的主要数据集。
2. **CIFAR-100**：包含5万训练图像和1万测试图像，100个类别。用于轻量级实验和快速验证。
3. **MS COCO**：用于目标检测和实例分割评估，包含11.8万训练图像和5千验证图像。

### 模型架构

我们在多种骨干网络上集成注意力模块：

- **ResNet系列**：ResNet-18, ResNet-50, ResNet-101
- **轻量级网络**：MobileNetV2, EfficientNet-B0
- **Transformer架构**：Vision Transformer (ViT-B/16)

### 注意力模块实现

我们实现了以下注意力模块，并提供了完整的PyTorch代码：

```{literalinclude} code/se_block.py
:language: python
:linenos:
:caption: SE模块实现
```

```{literalinclude} code/cbam.py
:language: python
:linenos:
:caption: CBAM模块实现
```

```{literalinclude} code/eca_block.py
:language: python
:linenos:
:caption: ECA模块实现
```

### 训练配置

所有实验使用相同的训练配置以确保公平比较：

```python
config = {
    'batch_size': 256,           # ImageNet
    'learning_rate': 0.1,        # 余弦退火
    'weight_decay': 1e-4,        # L2正则化
    'epochs': 100,               # 训练轮数
    'optimizer': 'SGD',          # 带动量的SGD
    'momentum': 0.9,
    'scheduler': 'cosine',       # 余弦退火学习率
    'label_smoothing': 0.1,      # 标签平滑
    'mixup_alpha': 0.2,          # Mixup数据增强
    'cutmix_alpha': 1.0,         # CutMix数据增强
}
```

<!-- ## 性能比较

### ImageNet分类结果

下表展示了在ImageNet-1K验证集上的Top-1和Top-5准确率。所有模型使用相同的训练设置，在4×V100 GPU上训练100个epoch。

```{list-table} 不同注意力机制的性能比较（ResNet-50骨干）
:header-rows: 1
:widths: 20 15 15 15 15

* - **模型**
  - **Top-1 Acc (%)**
  - **Top-5 Acc (%)**
  - **参数量 (M)**
  - **FLOPs (G)**
* - ResNet-50 (基线)
  - 76.15
  - 92.87
  - 25.56
  - 4.12
* - SE-ResNet-50
  - 77.62 (+1.47)
  - 93.79 (+0.92)
  - 28.09 (+2.53)
  - 4.13 (+0.01)
* - CBAM-ResNet-50
  - 78.49 (+2.34)
  - 94.31 (+1.44)
  - 28.11 (+2.55)
  - 4.14 (+0.02)
* - ECA-ResNet-50
  - 77.91 (+1.76)
  - 93.98 (+1.11)
  - 25.57 (+0.01)
  - 4.12 (+0.00)
* - BAM-ResNet-50
  - 77.92 (+1.77)
  - 94.02 (+1.15)
  - 28.10 (+2.54)
  - 4.14 (+0.02)
* - SKNet-50
  - 78.84 (+2.69)
  - 94.52 (+1.65)
  - 30.27 (+4.71)
  - 4.25 (+0.13)
```

### 轻量级网络上的表现

注意力机制在轻量级网络上的提升更为显著，因为这些网络通常特征表达能力有限。

```{list-table} MobileNetV2上的注意力机制性能
:header-rows: 1
:widths: 25 20 20 15

* - **模型**
  - **Top-1 Acc (%)**
  - **参数量 (M)**
  - **相对提升**
* - MobileNetV2 (基线)
  - 71.88
  - 3.50
  - -
* - + SE模块
  - 73.52
  - 3.53
  - +1.64
* - + CBAM模块
  - 73.89
  - 3.54
  - +2.01
* - + ECA模块
  - 73.41
  - 3.50
  - +1.53
```

### 目标检测性能

在MS COCO数据集上，我们使用Faster R-CNN框架，骨干网络为ResNet-50，评估注意力机制对目标检测的影响。

```{list-table} MS COCO目标检测结果（AP指标）
:header-rows: 1
:widths: 20 15 15 15 15

* - **模型**
  - **AP@[.5:.95]**
  - **AP@0.5**
  - **AP@0.75**
  - **AP_small**
* - Faster R-CNN (ResNet-50)
  - 37.4
  - 58.1
  - 40.4
  - 21.2
* - + SE模块
  - 39.1 (+1.7)
  - 60.2 (+2.1)
  - 42.3 (+1.9)
  - 23.1 (+1.9)
* - + CBAM模块
  - 39.8 (+2.4)
  - 61.0 (+2.9)
  - 43.1 (+2.7)
  - 24.0 (+2.8)
* - + ECA模块
  - 38.9 (+1.5)
  - 59.8 (+1.7)
  - 41.9 (+1.5)
  - 22.7 (+1.5)
```

## 消融研究

### CBAM组件消融

为了理解CBAM中各个组件的作用，我们在ResNet-50上进行了消融实验。

```{list-table} CBAM组件消融研究（ImageNet）
:header-rows: 1
:widths: 25 20 20 20

* - **配置**
  - **Top-1 Acc (%)**
  - **相对提升**
  - **计算开销 (GFLOPs)**
* - 基线 (ResNet-50)
  - 76.15
  - -
  - 4.12
* + 仅通道注意力 (CA)
  - 77.62
  - +1.47
  - 4.13
* + 仅空间注意力 (SA)
  - 77.28
  - +1.13
  - 4.13
* + CBAM (CA→SA 串行)
  - 78.49
  - +2.34
  - 4.14
* + CBAM (SA→CA 串行)
  - 78.32
  - +2.17
  - 4.14
* + CBAM (并行融合)
  - 78.12
  - +1.97
  - 4.14
* + CBAM (带最大池化+平均池化)
  - 78.49
  - +2.34
  - 4.14
* + CBAM (仅平均池化)
  - 78.21
  - +2.06
  - 4.13
```

### 插入位置消融

注意力模块可以插入到残差块的不同位置。我们测试了三种插入策略：

1. **前置**：在第一个卷积之前插入
2. **中间**：在两个卷积之间插入
3. **后置**：在第二个卷积之后、残差连接之前插入（标准位置）

```{list-table} 插入位置对性能的影响（SE模块，ResNet-50）
:header-rows: 1
:widths: 25 20 20

* - **插入位置**
  - **Top-1 Acc (%)**
  - **训练稳定性**
* - 前置 (before conv1)
  - 77.21
  - 中等
* - 中间 (between conv1 and conv2)
  - 77.58
  - 良好
* - 后置 (after conv2, before shortcut)
  - 77.62
  - 优秀
* - 双重 (both before and after)
  - 77.65
  - 优秀但参数量翻倍
```

### 压缩比 $r$ 的影响

通道注意力中的压缩比 $r$ 控制着瓶颈层的维度。我们测试了不同 $r$ 值对SE模块性能的影响。

```{list-table} 压缩比 $r$ 的影响（SE-ResNet-50）
:header-rows: 1
:widths: 20 20 20 20

* - **压缩比 $r$**
  - **Top-1 Acc (%)**
  - **参数量增加**
  - **训练速度 (imgs/sec)**
* - 无注意力 (基线)
  - 76.15
  - 0
  - 1250
* - $r=4$
  - 77.85
  - +10.24M
  - 1220
* - $r=8$
  - 77.70
  - +5.12M
  - 1235
* - $r=16$ (默认)
  - 77.62
  - +2.53M
  - 1245
* - $r=32$
  - 77.45
  - +1.28M
  - 1248
* - $r=64$
  - 77.28
  - +0.64M
  - 1249
```

## 计算效率分析

### 推理时间

我们在NVIDIA V100 GPU上测量了不同注意力模块的推理时间（batch size=32，输入尺寸224×224）。

```{list-table} 推理时间比较（ResNet-50）
:header-rows: 1
:widths: 25 20 20 20

* - **模型**
  - **推理时间 (ms)**
  - **内存占用 (MB)**
  - **速度下降**
* - ResNet-50
  - 7.2
  - 1024
  - 0%
* - SE-ResNet-50
  - 7.3
  - 1040
  - 1.4%
* - CBAM-ResNet-50
  - 7.5
  - 1050
  - 4.2%
* - ECA-ResNet-50
  - 7.2
  - 1025
  - 0.3%
* - SKNet-50
  - 8.1
  - 1100
  - 12.5%
```

### 训练收敛速度

注意力机制不仅提升最终精度，还加速训练收敛。下图展示了训练过程中验证准确率的变化。

```{figure} ../../_static/images/attention-convergence.png
:width: 80%
:align: center

不同注意力机制在ImageNet训练中的收敛曲线。注意力模型（尤其是CBAM）在早期epoch就达到较高准确率。
```

## 可视化分析

### 注意力图可视化

我们使用Grad-CAM技术可视化网络关注区域。下图比较了基线ResNet-50和CBAM-ResNet-50在图像分类任务中的注意力图。

```{figure} ../../_static/images/attention-visualization.png
:width: 80%
:align: center

注意力可视化：第一行为原始图像，第二行为基线模型的注意力图，第三行为CBAM模型的注意力图。CBAM的注意力更加集中和准确。
```

### 通道注意力权重分布

我们统计了SE模块中通道注意力权重的分布。发现大约20%的通道获得权重>0.8（被显著增强），30%的通道获得权重<0.2（被显著抑制），其余通道权重在中间范围。这表明注意力机制确实实现了通道选择。 -->

## 实际应用建议

基于以上实验结果，我们提出以下实用建议：

1. **精度优先**：如果追求最高精度，推荐使用CBAM或SKNet，尽管它们增加了一些计算开销。
2. **效率优先**：如果计算资源有限，推荐使用ECA模块，它在几乎不增加计算成本的情况下提供显著提升。
3. **轻量级网络**：对于MobileNet等轻量级网络，SE模块是性价比最高的选择。
4. **目标检测**：对于检测任务，CBAM提供最大提升，因为其空间注意力组件有助于定位。
5. **压缩比选择**：对于SE模块，$r=16$ 是较好的权衡；如果模型非常大（如ResNet-152），可以尝试 $r=8$。

## 结论

实验表明，注意力机制在各种视觉任务上都能带来一致的性能提升。通道注意力更适合分类任务，空间注意力更适合定位任务，而结合两者的混合注意力（如CBAM）在大多数任务上表现最佳。

尽管注意力模块增加了少量计算开销，但其带来的性能提升通常远超过开销。随着硬件优化和注意力模块的进一步轻量化，注意力机制已成为现代深度学习架构不可或缺的组成部分。

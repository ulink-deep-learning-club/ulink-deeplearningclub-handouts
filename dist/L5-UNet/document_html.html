<!DOCTYPE html>
<html lang="en-US">
<head>
<meta charset="UTF-8" />
<meta name="generator" content="LaTeX Lwarp package" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<title>U‑Net 架构：生物医学图像分割的革命性方法 </title>
<link rel="stylesheet" type="text/css" href="lwarp.css" />

<script>
// Lwarp MathJax emulation code
//
// Based on code by Davide P. Cervone.
// Equation numbering: https://github.com/mathjax/MathJax/issues/2427
// Starred and ifnextchar macros: https://github.com/mathjax/MathJax/issues/2428
// \left, \right delimiters: https://github.com/mathjax/MathJax/issues/2535
//
// Modified by Brian Dunn to adjust equation numbering and add subequations.
//
// LaTeX can use \seteqnumber{subequations?}{section}{number} before each equation.
// subequations? is 0 usually, 1 if inside subequations.
// section is a string printed as-is, or empty.
// number is auto-incremented by MathJax between equations.
//
MathJax = {
    subequations: "0",
    section: "",
    loader: {
        load: ['[tex]/tagformat', '[tex]/textmacros'],
    },
    startup: {
        ready() {
            //       These would be replaced by import commands if you wanted to make
            //       a proper extension.
            const Configuration = MathJax._.input.tex.Configuration.Configuration;
            const CommandMap = MathJax._.input.tex.SymbolMap.CommandMap;
            const Macro = MathJax._.input.tex.Symbol.Macro;
            const TexError = MathJax._.input.tex.TexError.default;
            const ParseUtil = MathJax._.input.tex.ParseUtil.default;
            const expandable = MathJax._.util.Options.expandable;


            //       Insert the replacement string into the TeX string, and check
            //       that there haven't been too many maxro substitutions (prevents
            //       infinite loops).
            const useArgument = (parser, text) => {
                parser.string = ParseUtil.addArgs(parser, text, parser.string.slice(parser.i));
                parser.i = 0;
                if (++parser.macroCount > parser.configuration.options.maxMacros) {
                     throw new TexError('MaxMacroSub1',
                     'MathJax maximum macro substitution count exceeded; ' +
                     'is there a recursive macro call?');
                }
            }


            //       Create the command map for:
            //           \ifstar, \ifnextchar, \ifblank, \ifstrequal, \gsub, \seteqnumber
            new CommandMap('Lwarp-macros', {
                ifstar: 'IfstarFunction',
                ifnextchar: 'IfnextcharFunction',
                ifblank: 'IfblankFunction',
                ifstrequal: 'IfstrequalFunction',
                gsubstitute: 'GsubstituteFunction',
                seteqnumber: 'SeteqnumberFunction'
            }, {
                //       This function implements an ifstar macro.
                IfstarFunction(parser, name) {
                     const resultstar = parser.GetArgument(name);
                     const resultnostar = parser.GetArgument(name);
                     const star = parser.GetStar();                      // true if there is a *
                     useArgument(parser, star ? resultstar : resultnostar);
                },


                //       This function implements an ifnextchar macro.
                IfnextcharFunction(parser, name) {
                     let whichchar = parser.GetArgument(name);
                     if (whichchar.match(/^(?:0x[0-9A-F]+|[0-9]+)$/i)) {
                         // $ syntax highlighting
                         whichchar = String.fromCodePoint(parseInt(whichchar));
                     }
                     const resultnextchar = parser.GetArgument(name);
                     const resultnotnextchar = parser.GetArgument(name);
                     const gotchar = (parser.GetNext() === whichchar);
                     useArgument(parser, gotchar ? resultnextchar : resultnotnextchar);
                },


                // This function implements an ifblank macro.
                IfblankFunction(parser, name) {
                     const blankarg = parser.GetArgument(name);
                     const resultblank = parser.GetArgument(name);
                     const resultnotblank = parser.GetArgument(name);
                     const isblank = (blankarg.trim() == "");
                     useArgument(parser, isblank ? resultblank : resultnotblank);
                },


                // This function implements an ifstrequal macro.
                IfstrequalFunction(parser, name) {
                     const strequalfirst = parser.GetArgument(name);
                     const strequalsecond = parser.GetArgument(name);
                     const resultequal = parser.GetArgument(name);
                     const resultnotequal = parser.GetArgument(name);
                     const isequal = (strequalfirst == strequalsecond);
                     useArgument(parser, isequal ? resultequal : resultnotequal);
                },


                // This function implements a gsub macro.
                GsubstituteFunction(parser, name) {
                     const gsubfirst = parser.GetArgument(name);
                     const gsubsecond = parser.GetArgument(name);
                     const gsubthird = parser.GetArgument(name);
                     let gsubresult=gsubfirst.replace(gsubsecond, gsubthird);
                     useArgument(parser, gsubresult);
                },


                //       This function modifies the equation numbers.
                SeteqnumberFunction(parser, name) {
                         // Get the macro parameters
                         const star = parser.GetStar();                    // true if there is a *
                         const optBrackets = parser.GetBrackets(name);     // contents of optional brackets
                         const newsubequations = parser.GetArgument(name);    // the subequations argument
                         const neweqsection = parser.GetArgument(name);    // the eq section argument
                         const neweqnumber = parser.GetArgument(name);     // the eq number argument
                         MathJax.config.subequations=newsubequations ;     // a string with boolean meaning
                         MathJax.config.section=neweqsection ;             // a string with numeric meaning
                         parser.tags.counter = parser.tags.allCounter = neweqnumber ;
                }


            });


            //       Create the Lwarp-macros package
            Configuration.create('Lwarp-macros', {
                handler: {macro: ['Lwarp-macros']}
            });


            MathJax.startup.defaultReady();


            // For forward references:
            MathJax.startup.input[0].preFilters.add(({math}) => {
                if (math.inputData.recompile){
                         MathJax.config.subequations = math.inputData.recompile.subequations;
                         MathJax.config.section = math.inputData.recompile.section;
                }
            });
            MathJax.startup.input[0].postFilters.add(({math}) => {
                if (math.inputData.recompile){
                         math.inputData.recompile.subequations = MathJax.config.subequations;
                         math.inputData.recompile.section = MathJax.config.section;
                }
            });


                // For \left, \right with unicode-math:
                const {DelimiterMap} = MathJax._.input.tex.SymbolMap;
                const {Symbol} = MathJax._.input.tex.Symbol;
                const {MapHandler} = MathJax._.input.tex.MapHandler;
                const delimiter = MapHandler.getMap('delimiter');
                delimiter.add('\\lBrack', new Symbol('\\lBrack', '\u27E6'));
                delimiter.add('\\rBrack', new Symbol('\\rBrack', '\u27E7'));
                delimiter.add('\\lAngle', new Symbol('\\lAngle', '\u27EA'));
                delimiter.add('\\rAngle', new Symbol('\\rAngle', '\u27EB'));
                delimiter.add('\\lbrbrak', new Symbol('\\lbrbrak', '\u2772'));
                delimiter.add('\\rbrbrak', new Symbol('\\rbrbrak', '\u2773'));
                delimiter.add('\\lbag', new Symbol('\\lbag', '\u27C5'));
                delimiter.add('\\rbag', new Symbol('\\rbag', '\u27C6'));
                delimiter.add('\\llparenthesis', new Symbol('\\llparenthesis', '\u2987'));
                delimiter.add('\\rrparenthesis', new Symbol('\\rrparenthesis', '\u2988'));
                delimiter.add('\\llangle', new Symbol('\\llangle', '\u2989'));
                delimiter.add('\\rrangle', new Symbol('\\rrangle', '\u298A'));
                delimiter.add('\\Lbrbrak', new Symbol('\\Lbrbrak', '\u27EC'));
                delimiter.add('\\Rbrbrak', new Symbol('\\Rbrbrak', '\u27ED'));
                delimiter.add('\\lBrace', new Symbol('\\lBrace', '\u2983'));
                delimiter.add('\\rBrace', new Symbol('\\rBrace', '\u2984'));
                delimiter.add('\\lParen', new Symbol('\\lParen', '\u2985'));
                delimiter.add('\\rParen', new Symbol('\\rParen', '\u2986'));
                delimiter.add('\\lbrackubar', new Symbol('\\lbrackubar', '\u298B'));
                delimiter.add('\\rbrackubar', new Symbol('\\rbrackubar', '\u298C'));
                delimiter.add('\\lbrackultick', new Symbol('\\lbrackultick', '\u298D'));
                delimiter.add('\\rbracklrtick', new Symbol('\\rbracklrtick', '\u298E'));
                delimiter.add('\\lbracklltick', new Symbol('\\lbracklltick', '\u298F'));
                delimiter.add('\\rbrackurtick', new Symbol('\\rbrackurtick', '\u2990'));
                delimiter.add('\\langledot', new Symbol('\\langledot', '\u2991'));
                delimiter.add('\\rangledot', new Symbol('\\rangledot', '\u2992'));
                delimiter.add('\\lparenless', new Symbol('\\lparenless', '\u2993'));
                delimiter.add('\\rparengtr', new Symbol('\\rparengtr', '\u2994'));
                delimiter.add('\\Lparengtr', new Symbol('\\Lparengtr', '\u2995'));
                delimiter.add('\\Rparenless', new Symbol('\\Rparenless', '\u2996'));
                delimiter.add('\\lblkbrbrak', new Symbol('\\lblkbrbrak', '\u2997'));
                delimiter.add('\\rblkbrbrak', new Symbol('\\rblkbrbrak', '\u2998'));
                delimiter.add('\\lvzigzag', new Symbol('\\lvzigzag', '\u29D8'));
                delimiter.add('\\rvzigzag', new Symbol('\\rvzigzag', '\u29D9'));
                delimiter.add('\\Lvzigzag', new Symbol('\\Lvzigzag', '\u29DA'));
                delimiter.add('\\Rvzigzag', new Symbol('\\Rvzigzag', '\u29DB'));
                delimiter.add('\\lcurvyangle', new Symbol('\\lcurvyangle', '\u29FC'));
                delimiter.add('\\rcurvyangle', new Symbol('\\rcurvyangle', '\u29FD'));
                delimiter.add('\\Vvert', new Symbol('\\Vvert', '\u2980'));
        }        // ready
    },           // startup


    tex: {
        packages: {'[+]': ['tagformat', 'Lwarp-macros', 'textmacros']},
        tags: "ams",
                tagformat: {
                         number: function (n) {
                              if(MathJax.config.subequations==0)
                                 return(MathJax.config.section + n);
                              else
                                 return(MathJax.config.section + String.fromCharCode(96+n));
                         },
                },
    }
}
</script>


<script
        id="MathJax-script"
        src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js"
></script>


</head>
<body>
<!--|Using lwarp|document.html|-->



<div class="bodywithoutsidetoc">



<main class="bodycontainer">



<section class="textbody">

<a id="document-autofile-0"></a>

<!--MathJax customizations:-->
<div data-nosnippet
         style="display:none"
>

\(\newcommand{\footnotename}{footnote}\)

\(\def \LWRfootnote {1}\)

\(\newcommand {\footnote }[2][\LWRfootnote ]{{}^{\mathrm {#1}}}\)

\(\newcommand {\footnotemark }[1][\LWRfootnote ]{{}^{\mathrm {#1}}}\)

\(\let \LWRorighspace \hspace \)

\(\renewcommand {\hspace }{\ifstar \LWRorighspace \LWRorighspace }\)

\(\newcommand {\TextOrMath }[2]{#2}\)

\(\newcommand {\mathnormal }[1]{{#1}}\)

\(\newcommand \ensuremath [1]{#1}\)

\(\newcommand {\LWRframebox }[2][]{\fbox {#2}} \newcommand {\framebox }[1][]{\LWRframebox } \)

\(\newcommand {\setlength }[2]{}\)

\(\newcommand {\addtolength }[2]{}\)

\(\newcommand {\setcounter }[2]{}\)

\(\newcommand {\addtocounter }[2]{}\)

\(\newcommand {\arabic }[1]{}\)

\(\newcommand {\number }[1]{}\)

\(\newcommand {\noalign }[1]{\text {#1}\notag \\}\)

\(\newcommand {\cline }[1]{}\)

\(\newcommand {\directlua }[1]{\text {(directlua)}}\)

\(\newcommand {\luatexdirectlua }[1]{\text {(directlua)}}\)

\(\newcommand {\protect }{}\)

\(\def \LWRabsorbnumber #1 {}\)

\(\def \LWRabsorbquotenumber &quot;#1 {}\)

\(\newcommand {\LWRabsorboption }[1][]{}\)

\(\newcommand {\LWRabsorbtwooptions }[1][]{\LWRabsorboption }\)

\(\def \mathchar {\ifnextchar &quot;\LWRabsorbquotenumber \LWRabsorbnumber }\)

\(\def \mathcode #1={\mathchar }\)

\(\let \delcode \mathcode \)

\(\let \delimiter \mathchar \)

\(\def \oe {\unicode {x0153}}\)

\(\def \OE {\unicode {x0152}}\)

\(\def \ae {\unicode {x00E6}}\)

\(\def \AE {\unicode {x00C6}}\)

\(\def \aa {\unicode {x00E5}}\)

\(\def \AA {\unicode {x00C5}}\)

\(\def \o {\unicode {x00F8}}\)

\(\def \O {\unicode {x00D8}}\)

\(\def \l {\unicode {x0142}}\)

\(\def \L {\unicode {x0141}}\)

\(\def \ss {\unicode {x00DF}}\)

\(\def \SS {\unicode {x1E9E}}\)

\(\def \dag {\unicode {x2020}}\)

\(\def \ddag {\unicode {x2021}}\)

\(\def \P {\unicode {x00B6}}\)

\(\def \copyright {\unicode {x00A9}}\)

\(\def \pounds {\unicode {x00A3}}\)

\(\let \LWRref \ref \)

\(\renewcommand {\ref }{\ifstar \LWRref \LWRref }\)

\( \newcommand {\multicolumn }[3]{#3}\)

\(\require {textcomp}\)

\(\newcommand {\intertext }[1]{\text {#1}\notag \\}\)

\(\let \Hat \hat \)

\(\let \Check \check \)

\(\let \Tilde \tilde \)

\(\let \Acute \acute \)

\(\let \Grave \grave \)

\(\let \Dot \dot \)

\(\let \Ddot \ddot \)

\(\let \Breve \breve \)

\(\let \Bar \bar \)

\(\let \Vec \vec \)

\(\newcommand {\toprule }[1][]{\hline }\)

\(\let \midrule \toprule \)

\(\let \bottomrule \toprule \)

\(\def \LWRbooktabscmidruleparen (#1)#2{}\)

\(\newcommand {\LWRbooktabscmidrulenoparen }[1]{}\)

\(\newcommand {\cmidrule }[1][]{\ifnextchar (\LWRbooktabscmidruleparen \LWRbooktabscmidrulenoparen }\)

\(\newcommand {\morecmidrules }{}\)

\(\newcommand {\specialrule }[3]{\hline }\)

\(\newcommand {\addlinespace }[1][]{}\)

\(\newcommand {\tcbset }[1]{}\)

\(\newcommand {\tcbsetforeverylayer }[1]{}\)

\(\newcommand {\tcbox }[2][]{\boxed {\text {#2}}}\)

\(\newcommand {\tcboxfit }[2][]{\boxed {#2}}\)

\(\newcommand {\tcblower }{}\)

\(\newcommand {\tcbline }{}\)

\(\newcommand {\tcbtitle }{}\)

\(\newcommand {\tcbsubtitle [2][]{\mathrm {#2}}}\)

\(\newcommand {\tcboxmath }[2][]{\boxed {#2}}\)

\(\newcommand {\tcbhighmath }[2][]{\boxed {#2}}\)

</div>

<a id="document-autopage-1"></a>
<div class="titlepage">

<h1><b>U‑Net 架构：生物医学图像分割的革命性方法 </b></h1>



<div class="author">



<div class="oneauthor">

<p>
Anson, 深度学习社
</p>
</div>

</div>



<div class="titledate">

<p>
2025 年 12 月 3 日
</p>
</div>

</div>
<div class="abstract">



<div class="abstracttitle"> 摘要 </div>

<p>
U‑Net 是一种专为生物医学图像分割设计的深度神经网络架构，自 2015 年提出以来已成为计算机视觉领域的里程碑式工作。本文深入分析了 U‑Net 架构的设计理念、核心创新点及其广泛应用。通过详细阐述编码器‑解码器结构、跳
跃连接、扩张卷积等关键概念，我们解释了 U‑Net 如何解决像素级分割任务中的挑战。文章不仅涵盖了 U‑Net 的数学基础和实现细节，还探讨了其在医学影像、卫星图像分析等领域的应用，以及后续的改进变体如 U‑Net++、
Attention U‑Net 等。通过大量的图示和实际应用案例，本文为读者提供了全面理解 U‑Net 架构及其在图像分割任务中卓越性能的完整指南。
</p>
</div>
<!--
...... section 目录......
-->
<h4 id="autosec-4">目录</h4>
<a id="document-autopage-4"></a>




<nav class="toc">

</nav>
<!--
...... section 引言......
-->
<h4 id="autosec-5"><span class="sectionnumber">1&#x2003;</span>引言</h4>
<a id="document-autopage-5"></a>
<!--
...... subsection 图像分割的重要性与挑战......
-->
<h5 id="autosec-6"><span class="sectionnumber">1.1&#x2003;</span>图像分割的重要性与挑战</h5>
<a id="document-autopage-6"></a>



<p>
图像分割是计算机视觉中的核心任务之一，其目标是将图像划分为多个有意义的区域，每个区域对应于特定的对象或语义类别。与图像分类（整个图像的类别预测）和目标检测（边界框定位）不同，图像分割要求对每个像素进行精
确分类，这是一种像素级的预测任务。
</p>



<div
      class="tcolorbox"
      style=" border: 1px solid #404040; background: #F2F2F2; "
>



<div
      class="tcolorboxtitle"
      style=" border-top: 1px solid #404040; border-bottom: 1px solid #404040; background: #404040; color: #FFFFFF; "
>

<p>
<b> 图像分割的关键挑战 </b>
</p>
</div>



<div
      class="tcolorboxupper"
      style=" color: #000000; "
>

<ul class="itemize" style="list-style-type:none">


<li>
<p>
<span class="listmarker">‧</span> <b> 空间精度要求：</b> 需要精确的边界定位，不能遗漏细节
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 多尺度信息：</b> 需要同时捕捉局部细节和全局上下文
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 类别不平衡：</b> 某些类别像素可能很少，容易忽略
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 计算复杂度：</b> 高分辨率图像的像素级预测计算开销巨大
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 标注数据稀缺：</b> 像素级标注成本高昂，训练数据有限
</p>
</li>
</ul>

</div>

</div>
<!--
...... subsection U-Net 的诞生背景......
-->
<h5 id="autosec-7"><span class="sectionnumber">1.2&#x2003;</span>U‑Net 的诞生背景</h5>
<a id="document-autopage-7"></a>



<p>
U‑Net 最初由 Olaf Ronneberger 等人于 2015 年提出，专门用于解决生物医学图像分割问题。其名称来源于网络架构的 U 形对称结构。在 ISBI 2012 的细胞分割挑战赛中，U‑Net 以显著优势获胜，证明了其在生物医学图像分割任
务上的卓越性能。
</p>



<div
      class="tcolorbox"
      style=" border: 1px solid #404040; background: #F2F2F2; "
>



<div
      class="tcolorboxtitle"
      style=" border-top: 1px solid #404040; border-bottom: 1px solid #404040; background: #404040; color: #FFFFFF; "
>

<p>
<b>U‑Net 的设计动机 </b>
</p>
</div>



<div
      class="tcolorboxupper"
      style=" color: #000000; "
>

<ul class="itemize" style="list-style-type:none">


<li>
<p>
<span class="listmarker">‧</span> <b> 生物医学图像特殊性：</b> 样本数量有限、边界模糊、对比度低
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 精确分割需求：</b> 医学诊断要求极高的边界精度
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 实时处理要求：</b> 临床应用需要快速的推理速度
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 少样本学习：</b> 需要在有限训练数据下取得良好效果
</p>
</li>
</ul>

</div>

</div>
<!--
...... section U-Net 架构详解......
-->
<h4 id="autosec-8"><span class="sectionnumber">2&#x2003;</span>U‑Net 架构详解</h4>
<a id="document-autopage-8"></a>
<!--
...... subsection 整体架构设计......
-->
<h5 id="autosec-9"><span class="sectionnumber">2.1&#x2003;</span>整体架构设计</h5>
<a id="document-autopage-9"></a>



<p>
U‑Net 采用经典的编码器‑解码器（Encoder‑Decoder）架构，呈现出对称的 U 形结构。编码器部分通过下采样逐步提取高层次特征，解码器部分通过上采样逐步恢复空间分辨率，最终输出与输入相同尺寸的分割图。
</p>

<figure id="autoid-1" class="figure ">
<div class="center">



<div class="figurecaption">


图&nbsp;1: 完整的 U‑Net 架构图，展示编码器‑解码器 U 形结构、跳跃连接和特征维度变化

</div>

<a id="fig:unet_architecture"></a>

</div>

</figure>



<div
      class="tcolorbox"
      style=" border: 1px solid #404040; background: #F2F2F2; "
>



<div
      class="tcolorboxtitle"
      style=" border-top: 1px solid #404040; border-bottom: 1px solid #404040; background: #404040; color: #FFFFFF; "
>

<p>
<b> 核心组件说明 </b>
</p>
</div>



<div
      class="tcolorboxupper"
      style=" color: #000000; "
>

<ul class="itemize" style="list-style-type:none">


<li>
<p>
<span class="listmarker">‧</span> <b> 编码器路径（Contracting Path）：</b> 类似于典型的卷积神经网络，通过卷积和下采样操作提取特征
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 解码器路径（Expansive Path）：</b> 通过上采样和卷积操作恢复空间分辨率
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 跳跃连接：</b> 连接编码器和解码器对应层，传递低层次细节信息
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 最终卷积层：</b> 1×1 卷积将特征映射到输出类别数
</p>
</li>
</ul>

</div>

</div>
<!--
...... subsection 编码器路径分析......
-->
<h5 id="autosec-11"><span class="sectionnumber">2.2&#x2003;</span>编码器路径分析</h5>
<a id="document-autopage-11"></a>



<p>
编码器路径遵循传统 CNN 的设计模式，每一步包含两个 3×3 卷积层（激活函数为 ReLU），然后接一个 2×2 最大池化层进行下采样。这种设计逐步提取更高级的特征，同时降低空间分辨率。
</p>

<figure id="autoid-2" class="figure ">
<div class="center">



<div class="figurecaption">


图&nbsp;2: U‑Net 中的双卷积块结构：两个 3×3 卷积层，每个后接 ReLU 激活函数

</div>

<a id="fig:double_conv"></a>

</div>

</figure>

<figure id="autoid-3" class="figure ">
<div class="center">



<div class="figurecaption">


图&nbsp;3: 2×2 最大池化下采样操作：空间分辨率减半，保持主要特征

</div>

<a id="fig:max_pooling"></a>

</div>

</figure>



<div
      class="tcolorbox"
      style=" border: 1px solid #404040; background: #F2F2F2; "
>



<div
      class="tcolorboxtitle"
      style=" border-top: 1px solid #404040; border-bottom: 1px solid #404040; background: #404040; color: #FFFFFF; "
>

<p>
<b> 编码器设计理由 </b>
</p>
</div>



<div
      class="tcolorboxupper"
      style=" color: #000000; "
>

<ul class="itemize" style="list-style-type:none">


<li>
<p>
<span class="listmarker">‧</span> <b> 特征层次化：</b> 浅层学习边缘和纹理，深层学习语义信息
</p>
<p>
<b> 详细解释：</b> 在编码器的不同层次，网络学习到不同抽象程度的特征。第一层卷积主要检测简单的边缘、角点和纹理模式；第二层可能学习到简单的形状和模式组合；更深的层次能够识别复杂的语义对象。这种层次化特征学
习模仿了人类视觉系统的处理机制，从简单到复杂逐步抽象。
</p>
</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 感受野扩大：</b> 下采样增大感受野，捕获全局上下文
</p>
<p>
<b> 数学原理：</b> 感受野的计算公式为：
</p>
<p>
\[RF_{l} = RF_{l-1} + (k_{l} - 1) \times \prod _{i=1}^{l-1} s_{i}\]
</p>
<p>
其中\(RF_l\) 是第\(l\) 层的感受野，\(k_l\) 是卷积核大小，\(s_i\) 是第\(i\) 层的步长。通过每次下采样，感受野呈指数级增长，使得深层神经元能够看到更大的输入区域，从而捕获全局上下文信息。
</p>
</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 参数效率：</b> 减少空间维度，降低计算复杂度
</p>
<p>
<b> 计算分析：</b> 假设输入图像大小为\(H \times W \times C\)，经过一层卷积后特征图大小为\(H&apos; \times W&apos; \times C&apos;\)，计算复杂度为\(O(H&apos; \times W&apos; \times C \times C&apos; \times k^2)\)。
通过下采样将空间维度减半，后续层的计算量减少为原来的\(1/4\)，显著提高了计算效率。
</p>
</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 平移不变性：</b> 池化操作增强模型的平移不变性
</p>
<p>
<b> 机制说明：</b> 最大池化选择局部区域内的最大值，使得当目标在输入中发生小范围平移时，池化后的特征表示相对稳定。这种平移不变性对于生物医学图像分割尤为重要，因为医学图像中的目标（如细胞、器官）可能出现在
图像的不同位置。
</p>
</li>
</ul>

</div>

</div>

<p>
每个下采样步骤后，特征通道数翻倍（64→128→256→512→1024），这确保了尽管空间分辨率降低，但特征表示能力不断增强。通道数的增加遵循信息论原理，用更多的通道来编码压缩后的空间信息，避免信息损失。
</p>

<figure id="autoid-4" class="figure ">
<div class="center">



<div class="figurecaption">


图&nbsp;4: U‑Net 与传统 CNN 架构对比：展示跳跃连接和编码器‑解码器结构差异

</div>

<a id="fig:unet_vs_cnn"></a>

</div>

</figure>
<!--
...... subsection 解码器路径设计......
-->
<h5 id="autosec-15"><span class="sectionnumber">2.3&#x2003;</span>解码器路径设计</h5>
<a id="document-autopage-15"></a>



<p>
解码器路径是 U‑Net 的创新所在。每一步都包含一个上采样操作，将特征图尺寸翻倍，然后与对应编码器层的特征图拼接，再经过两个 3×3 卷积层。
</p>

<figure id="autoid-5" class="figure ">
<div class="center">



<div class="figurecaption">


图&nbsp;5: 转置卷积上采样操作：将低分辨率特征图恢复到高分辨率空间

</div>

<a id="fig:transposed_conv"></a>

</div>

</figure>

<figure id="autoid-6" class="figure ">
<div class="center">



<div class="figurecaption">


图&nbsp;6: 跳跃连接中的特征融合：编码器特征与解码器特征的拼接操作

</div>

<a id="fig:feature_fusion"></a>

</div>

</figure>



<div
      class="tcolorbox"
      style=" border: 1px solid #404040; background: #F2F2F2; "
>



<div
      class="tcolorboxtitle"
      style=" border-top: 1px solid #404040; border-bottom: 1px solid #404040; background: #404040; color: #FFFFFF; "
>

<p>
<b> 解码器设计原理 </b>
</p>
</div>



<div
      class="tcolorboxupper"
      style=" color: #000000; "
>

<ul class="itemize" style="list-style-type:none">


<li>
<p>
<span class="listmarker">‧</span> <b> 空间恢复：</b> 上采样操作逐步恢复空间分辨率
</p>
<p>
<b> 转置卷积机制：</b> 转置卷积（也称为反卷积）通过在特征图元素之间插入零值，然后应用标准卷积来实现上采样。数学上，转置卷积是卷积操作的转置：
</p>
<p>
\[y = W^T \cdot x\]
</p>
<p>
其中\(W^T\) 是卷积核\(W\) 的转置，\(x\) 是输入特征。这种方法能够学习上采样过程中的最优权重，而不是简单的插值。
</p>
</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 特征融合：</b> 拼接操作结合高层语义和低层细节
</p>
<p>
<b> 拼接策略：</b> 假设编码器特征为\(F_{enc} \in \mathbb {R}^{H \times W \times C_1}\)，解码器特征为\(F_{dec} \in \mathbb {R}^{H \times W \times C_2}\)，拼接操作生成：
</p>
<p>
\[F_{concat} = \text {concat}(F_{enc}, F_{dec}) \in \mathbb {R}^{H \times W \times (C_1 + C_2)}\]
</p>
<p>
这种拼接保持了原始特征的所有信息，相比相加操作更丰富。
</p>
</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 信息补偿：</b> 弥补下采样过程中丢失的空间信息
</p>
<p>
<b> 信息流分析：</b> 在编码过程中，下采样会丢失一些空间细节。例如，2×2 最大池化会丢失 3/4 的位置信息。跳跃连接直接传递高分辨率的编码器特征，为解码器提供精确的空间坐标信息，这些信息对于像素级分割至关重要。
</p>
</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 精确边界：</b> 利用跳跃连接信息实现精确的边界定位
</p>
<p>
<b> 边界检测机制：</b> 浅层特征包含丰富的边缘和纹理信息，这些信息对边界定位非常敏感。通过跳跃连接，这些边界感知特征直接传递给解码器，使得最终分割能够保持清晰的边界轮廓。这在生物医学图像中尤为重要，因为细
胞和器官的边界通常很模糊且不规则。
</p>
</li>
</ul>

</div>

</div>
<!--
...... subsection 跳跃连接的革命性作用......
-->
<h5 id="autosec-18"><span class="sectionnumber">2.4&#x2003;</span>跳跃连接的革命性作用</h5>
<a id="document-autopage-18"></a>



<p>
跳跃连接是 U‑Net 最重要的创新，它直接连接编码器和解码器的对应层，将低层次的高分辨率特征传递给解码器。
</p>

<figure id="autoid-7" class="figure ">
<div class="center">



<div class="figurecaption">


图&nbsp;7: 跳跃连接详细可视化：展示信息流、特征维度变化和梯度路径

</div>

<a id="fig:skip_connection"></a>

</div>

</figure>



<div
      class="tcolorbox"
      style=" border: 1px solid #404040; background: #F2F2F2; "
>



<div
      class="tcolorboxtitle"
      style=" border-top: 1px solid #404040; border-bottom: 1px solid #404040; background: #404040; color: #FFFFFF; "
>

<p>
<b> 跳跃连接的作用机制 </b>
</p>
</div>



<div
      class="tcolorboxupper"
      style=" color: #000000; "
>

<ul class="itemize" style="list-style-type:none">


<li>
<p>
<span class="listmarker">‧</span> <b> 梯度流动：</b> 提供直接的梯度路径，缓解梯度消失问题
</p>
<p>
<b> 梯度流机制：</b> 在深度神经网络中，梯度通过链式法则反向传播时需要经历多次乘法操作。当梯度绝对值小于 1 时，连续相乘会导致梯度指数级衰减，这就是梯度消失问题。
</p>
<p>
<b> 数学分析：</b> 考虑一个 L 层的网络，没有跳跃连接时，第\(l\) 层的梯度为：
</p>
<p>
\[\frac {\partial L}{\partial W_l} = \frac {\partial L}{\partial \hat {y}} \prod _{i=l+1}^{L} \frac {\partial z_i}{\partial z_{i-1}} \frac {\partial z_i}{\partial W_i}\]
</p>
<p>
有跳跃连接时，梯度可以直接跳跃到浅层：
</p>
<p>
\[\frac {\partial L}{\partial W_l} = \frac {\partial L}{\partial \hat {y}} \left ( \prod _{i=l+1}^{L} \frac {\partial z_i}{\partial z_{i-1}} \frac {\partial z_i}{\partial W_i} + \frac {\partial
z_{skip}}{\partial W_l} \right )\]
</p>
<p>
跳跃连接为梯度提供了一条” 高速公路”，避免了深层网络中梯度的指数级衰减。
</p>
</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 细节保留：</b> 传递精细的空间信息和边界细节
</p>
<p>
<b> 信息层次理论：</b> 不同深度的特征图包含不同粒度的信息：
</p>
<ul class="itemize" style="list-style-type:none">


<li>
<p>
<span class="listmarker">–</span> <b> 浅层特征（第 1‑2 层）：</b> 原始像素级边缘、角点、纹理
</p>


</li>
<li>


<p>
<span class="listmarker">–</span> <b> 中层特征（第 3‑4 层）：</b> 简单形状、模式组合、局部结构
</p>


</li>
<li>


<p>
<span class="listmarker">–</span> <b> 深层特征（第 5‑6 层）：</b> 语义对象、高级概念、全局上下文
</p>
</li>
</ul>
<p>
跳跃连接将浅层的精细空间信息直接传递给解码器，确保最终分割结果保持精确的边界和细小结构。这在医学图像分割中特别重要，因为细胞边界、血管轮廓等细节对诊断至关重要。
</p>
</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 多尺度融合：</b> 结合不同感受野的特征信息
</p>
<p>
<b> 感受野级联：</b> U‑Net 中不同层次的特征图具有不同的感受野：
</p>
<span class="hidden"> \(\seteqnumber{0}{}{0}\)</span>


<!--



                                                                                               RF1 = 3 × 3                                                                                          (1)
                                                                                               RF2 = 5 × 5                                                                                          (2)
                                                                                               RF3 = 9 × 9                                                                                          (3)
                                                                                               RF4 = 17 × 17                                                                                        (4)
                                                                                               RF5 = 33 × 33                                                                                        (5)



-->


<p>


\begin{align}
RF_1 &amp;= 3 \times 3 \\ RF_2 &amp;= 5 \times 5 \\ RF_3 &amp;= 9 \times 9 \\ RF_4 &amp;= 17 \times 17 \\ RF_5 &amp;= 33 \times 33
\end{align}


</p>
<p>
跳跃连接将不同感受野的特征进行融合，使得每个解码器层都能同时获得局部细节和全局上下文。这种多尺度信息融合能力是 U‑Net 成功的关键因素之一。
</p>
</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 端到端学习：</b> 支持端到端的训练，不需要分阶段优化
</p>
<p>
<b> 训练稳定性：</b> 传统两阶段方法（先编码再解码）存在不稳定性，第一阶段学习的编码器可能不适应第二阶段的解码任务。U‑Net 的跳跃连接确保编码器和解码器能够协同训练，整个网络作为一个统一的整体进行优化。
</p>
<p>
<b> 联合优化目标：</b> 整个网络的最小化目标是：
</p>
<p>
\[\min _{\theta _{enc}, \theta _{dec}} \sum _{i=1}^{N} \mathcal {L}(y_i, f_{dec}(f_{enc}(x_i; \theta _{enc}); \theta _{dec}), y_i)\]
</p>
<p>
其中\(\theta _{enc}\) 和\(\theta _{dec}\) 分别是编码器和解码器的参数，它们通过跳跃连接紧密耦合，共同优化。
</p>
</li>
</ul>

</div>

</div>

<figure id="autoid-8" class="figure ">
<div class="center">



<div class="figurecaption">


图&nbsp;8: 梯度流动可视化：比较有无跳跃连接时的梯度传播路径

</div>

<a id="fig:gradient_flow"></a>

</div>

</figure>
<!--
...... subsection 激活函数与归一化选择......
-->
<h5 id="autosec-21"><span class="sectionnumber">2.5&#x2003;</span>激活函数与归一化选择</h5>
<a id="document-autopage-21"></a>
<!--
...... subsubsection ReLU 激活函数的合理性......
-->
<h6 id="autosec-22"><span class="sectionnumber">2.5.1&#x2003;</span>ReLU 激活函数的合理性</h6>
<a id="document-autopage-22"></a>



<p>
U‑Net 使用 ReLU（Rectified Linear Unit）作为激活函数，主要原因包括：
</p>
<ul class="itemize" style="list-style-type:none">


<li>
<p>
<span class="listmarker">‧</span> <b> 计算效率：</b> 简单的 max 操作，计算开销小
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 梯度特性：</b> 避免梯度消失，加速训练收敛
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 稀疏激活：</b> 产生稀疏表示，提高网络效率
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 生物启发：</b> 模拟神经元的激活特性
</p>
</li>
</ul>
<!--
...... subsubsection 批归一化的考虑......
-->
<h6 id="autosec-23"><span class="sectionnumber">2.5.2&#x2003;</span>批归一化的考虑</h6>
<a id="document-autopage-23"></a>



<p>
虽然原始 U‑Net 未使用批归一化，但现代实现通常添加批归一化层：
</p>
<ul class="itemize" style="list-style-type:none">


<li>
<p>
<span class="listmarker">‧</span> <b> 训练稳定性：</b> 减少内部协变量偏移，稳定训练过程
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 收敛加速：</b> 允许使用更高的学习率
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 梯度流改善：</b> 缓解梯度消失和爆炸问题
</p>
</li>
</ul>
<!--
...... section U-Net 的数学基础......
-->
<h4 id="autosec-24"><span class="sectionnumber">3&#x2003;</span>U‑Net 的数学基础</h4>
<a id="document-autopage-24"></a>
<!--
...... subsection 卷积操作的数学表述......
-->
<h5 id="autosec-25"><span class="sectionnumber">3.1&#x2003;</span>卷积操作的数学表述</h5>
<a id="document-autopage-25"></a>



<p>
U‑Net 的核心操作是卷积，其数学定义为：
</p>

<p>
\[y_{i,j} = \sum _{m=0}^{M-1} \sum _{n=0}^{N-1} x_{i+m,j+n} \cdot w_{m,n} + b\]
</p>

<p>
其中\(x\) 是输入特征图，\(w\) 是卷积核，\(b\) 是偏置项，\(y\) 是输出特征图。
</p>
<!--
...... subsection 最大池化的信息选择......
-->
<h5 id="autosec-26"><span class="sectionnumber">3.2&#x2003;</span>最大池化的信息选择</h5>
<a id="document-autopage-26"></a>



<p>
最大池化操作选择局部区域的最大值：
</p>

<p>
\[y_{i,j} = \max _{0 \leq m,n &lt; k} x_{i \cdot k + m, j \cdot k + n}\]
</p>

<p>
其中\(k\) 是池化核大小（通常为 2）。
</p>
<!--
...... subsection 上采样操作的实现......
-->
<h5 id="autosec-27"><span class="sectionnumber">3.3&#x2003;</span>上采样操作的实现</h5>
<a id="document-autopage-27"></a>



<p>
U‑Net 使用转置卷积（Transposed Convolution）进行上采样：
</p>

<p>
\[y = \text {Conv}^{T}(x, w)\]
</p>

<p>
转置卷积可以视为卷积的梯度操作，能够将低分辨率特征映射到高分辨率空间。
</p>
<!--
...... subsection 损失函数设计......
-->
<h5 id="autosec-28"><span class="sectionnumber">3.4&#x2003;</span>损失函数设计</h5>
<a id="document-autopage-28"></a>



<p>
对于图像分割任务，U‑Net 通常使用以下损失函数。损失函数的选择直接影响模型的训练效果和最终性能。
</p>

<figure id="autoid-9" class="figure ">
<div class="center">



<div class="figurecaption">


图&nbsp;9: 交叉熵损失用于像素级分类：展示每个像素的损失计算过程

</div>

<a id="fig:cross_entropy"></a>

</div>

</figure>
<!--
...... subsubsection 交叉熵损失......
-->
<h6 id="autosec-30"><span class="sectionnumber">3.4.1&#x2003;</span>交叉熵损失</h6>
<a id="document-autopage-30"></a>



<p>
交叉熵损失是像素级分类的标准损失函数，衡量预测分布与真实分布之间的差异：
</p>

<p>
\[\mathcal {L}_{CE} = -\frac {1}{HW} \sum _{i=1}^{H} \sum _{j=1}^{W} \sum _{c=1}^{C} y_{i,j,c} \log (\hat {y}_{i,j,c})\]
</p>

<p>
其中\(H, W\) 是图像高度和宽度，\(C\) 是类别数，\(y\) 是真实标签，\(\hat {y}\) 是预测概率。
</p>

<p>
<b> 数学原理和优势：</b>
</p>
<ul class="itemize" style="list-style-type:none">


<li>
<p>
<span class="listmarker">‧</span> <b> 信息理论基础：</b> 交叉熵源于信息论，表示两个概率分布之间的相对熵，反映了编码真实分布所需的额外信息量。
</p>
</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 凸函数特性：</b> 对于二分类问题，交叉熵损失是凸函数，具有良好的优化性质。
</p>
</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 概率解释：</b> 直接最大化似然函数，具有明确的概率意义。
</p>
</li>
</ul>

<p>
<b> 实际应用中的考虑：</b>
</p>
<ul class="itemize" style="list-style-type:none">


<li>
<p>
<span class="listmarker">‧</span> <b> 数值稳定性：</b> 为避免\(\log (0)\) 计算，实际实现中使用\(\log (\hat {y} + \epsilon )\)，其中\(\epsilon \) 是很小的常数（如\(10^{-8}\)）。
</p>
</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 梯度特性：</b> 对于预测接近 0 或 1 的情况，梯度会变得很小，可能导致训练饱和。
</p>
</li>
</ul>

<figure id="autoid-10" class="figure ">
<div class="center">



<div class="figurecaption">


图&nbsp;10: Dice 损失处理类别不平衡：展示重叠度计算和损失函数特性

</div>

<a id="fig:dice_loss"></a>

</div>

</figure>
<!--
...... subsubsection Dice 损失......
-->
<h6 id="autosec-32"><span class="sectionnumber">3.4.2&#x2003;</span>Dice 损失</h6>
<a id="document-autopage-32"></a>



<p>
Dice 损失是一种专门为图像分割设计的损失函数，特别适用于处理类别不平衡问题。让我们从最基础的概念开始，逐步理解 Dice 损失的工作原理。
</p>

<p>
<b> 从直观理解开始：</b>
</p>

<p>
想象你有两张透明的图片，一张是真实的分割结果（Ground Truth），另一张是模型预测的分割结果。如果你把这两张图片叠加在一起，Dice 系数就是测量它们重叠程度的标准。
</p>

<figure id="autoid-11" class="figure ">
<div class="center">



<div class="figurecaption">


图&nbsp;11: Dice 系数的直观理解：两个圆圈的重叠程度，完全重合时 Dice=1，完全分离时 Dice=0

</div>

<a id="fig:dice_intuitive"></a>

</div>

</figure>

<p>
<b>Dice 系数的基本公式：</b>
</p>

<p>
\[\text {Dice}(A, B) = \frac {2 \times |A \cap B|}{|A| + |B|}\]
</p>

<p>
让我们分解这个公式的每个部分：
</p>



<div
      class="tcolorbox"
      style=" border: 1px solid #404040; background: #F2F2F2; "
>



<div
      class="tcolorboxtitle"
      style=" border-top: 1px solid #404040; border-bottom: 1px solid #404040; background: #404040; color: #FFFFFF; "
>

<p>
<b> 公式详解 </b>
</p>
</div>



<div
      class="tcolorboxupper"
      style=" color: #000000; "
>

<ul class="itemize" style="list-style-type:none">


<li>
<p>
<span class="listmarker">‧</span> <b>\(A \cap B\)</b>：两个集合的交集，即两张图片中都标记为” 目标” 的像素
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b>\(|A|\)</b>：真实标注中目标像素的总数量
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b>\(|B|\)</b>：模型预测中目标像素的总数量
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b>\(|A \cap B|\)</b>：两者都认为是目标的像素数量（正确预测的像素）
</p>
</li>
</ul>

</div>

</div>

<p>
<b> 为什么选择 Dice 系数？</b>
</p>

<p>
Dice 系数有几个重要特性，使其非常适合图像分割：
</p>

<ul class="enumerate" style="list-style-type:none">


<li>
<p>
<span class="listmarker">1.</span> <b> 范围在 [0, 1] 之间：</b>
</p>
<ul class="itemize" style="list-style-type:none">


<li>
<p>
<span class="listmarker">‧</span> Dice = 1：完美重叠，分割完全正确
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> Dice = 0：完全没有重叠，分割完全错误
</p>
</li>
</ul>
</li>
<li>


<p>
<span class="listmarker">2.</span> <b> 对称性：</b> \(\text {Dice}(A, B) = \text {Dice}(B, A)\)，这很合理，因为重叠程度与观察顺序无关
</p>
</li>
<li>


<p>
<span class="listmarker">3.</span> <b> 同时考虑召回率和精确率：</b> Dice 系数实际上是 F1‑score 的另一种形式
</p>
</li>
</ul>

<p>
<b> 从 Dice 系数到 Dice 损失：</b>
</p>

<p>
由于深度学习框架通常是最小化损失，而不是最大化指标，我们将其转换为损失函数：
</p>

<p>
\[\mathcal {L}_{Dice} = 1 - \text {Dice}(A, B) = 1 - \frac {2|A \cap B|}{|A| + |B|}\]
</p>

<p>
这意味着：
</p>
<ul class="itemize" style="list-style-type:none">


<li>
<p>
<span class="listmarker">‧</span> 完美分割（Dice=1）→ 损失 =0
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> 完全错误分割（Dice=0）→ 损失 =1
</p>
</li>
</ul>

<p>
<b> 像素级别的计算：</b>
</p>

<p>
在图像分割中，我们需要对每个像素进行计算。假设我们有以下符号：
</p>
<ul class="itemize" style="list-style-type:none">


<li>
<p>
<span class="listmarker">‧</span> \(y_{i,j}\)：像素\((i,j)\) 的真实标签（1 表示目标，0 表示背景）
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> \(\hat {y}_{i,j}\)：像素\((i,j)\) 的预测概率（0 到 1 之间）
</p>
</li>
</ul>

<p>
那么 Dice 损失可以写成：
</p>

<p>
\[\mathcal {L}_{Dice} = 1 - \frac {2\sum _{i,j} y_{i,j} \cdot \hat {y}_{i,j}}{\sum _{i,j} y_{i,j} + \sum _{i,j} \hat {y}_{i,j}}\]
</p>

<p>
<b> 具体计算示例：</b>
</p>

<p>
让我们用一个简单的例子来说明 Dice 损失的计算过程。考虑一个 4×4 的小图像：
</p>



<div
      class="tcolorbox"
      style=" border: 1px solid #404040; background: #F2F2F2; "
>



<div
      class="tcolorboxtitle"
      style=" border-top: 1px solid #404040; border-bottom: 1px solid #404040; background: #404040; color: #FFFFFF; "
>

<p>
<b> 计算示例 </b>
</p>
</div>



<div
      class="tcolorboxupper"
      style=" color: #000000; "
>

<figure id="autoid-12" class="table ">
<div class="center">
<table>

<tr style="display:none"><th>.</th></tr>


<tr class="hline">
<td colspan="2" class="tdc tvertbarl tvertbarr" style="border-left: 1px solid black; border-right: 1px solid black"><b> 真实标注 </b></td>
<td colspan="2" class="tdc tvertbarr" style="border-right: 1px solid black"><b> 预测结果 </b></td>
</tr>


<tr class="hline">
<td class="tdc tvertbarl tvertbarr" style="border-left: 1px solid black; border-right: 1px solid black">0</td>
<td class="tdc tvertbarr" style="border-right: 1px solid black">0</td>
<td class="tdc tvertbarr" style="border-right: 1px solid black">0</td>
<td class="tdc tvertbarr" style="border-right: 1px solid black">0</td>
</tr>


<tr>
<td class="tdc tvertbarl tvertbarr" style="border-left: 1px solid black; border-right: 1px solid black">0</td>
<td class="tdc tvertbarr" style="border-right: 1px solid black"><span
      class="textcolor"
      style="color:#FF0000"
>1</span></td>
<td class="tdc tvertbarr" style="border-right: 1px solid black"><span
      class="textcolor"
      style="color:#FF0000"
>1</span></td>
<td class="tdc tvertbarr" style="border-right: 1px solid black">0</td>
</tr>


<tr>
<td class="tdc tvertbarl tvertbarr" style="border-left: 1px solid black; border-right: 1px solid black"><span
      class="textcolor"
      style="color:#FF0000"
>1</span></td>
<td class="tdc tvertbarr" style="border-right: 1px solid black"><span
      class="textcolor"
      style="color:#FF0000"
>1</span></td>
<td class="tdc tvertbarr" style="border-right: 1px solid black"><span
      class="textcolor"
      style="color:#FF0000"
>1</span></td>
<td class="tdc tvertbarr" style="border-right: 1px solid black"><span
      class="textcolor"
      style="color:#FF0000"
>1</span></td>
</tr>


<tr>
<td class="tdc tvertbarl tvertbarr" style="border-left: 1px solid black; border-right: 1px solid black">0</td>
<td class="tdc tvertbarr" style="border-right: 1px solid black"><span
      class="textcolor"
      style="color:#FF0000"
>1</span></td>
<td class="tdc tvertbarr" style="border-right: 1px solid black">0</td>
<td class="tdc tvertbarr" style="border-right: 1px solid black">0</td>
</tr>


<tr class="hline" aria-hidden="true">
<td class="tdc"></td>
<td class="tdc"></td>
<td class="tdc"></td>
<td class="tdc"></td>
</tr>
</table>

</div>

</figure>

<ul class="enumerate" style="list-style-type:none">


<li>
<p>
<span class="listmarker">1.</span> <b> 计算交集 </b>：真实和预测都为 1 的像素数 = 3 个
</p>


</li>
<li>


<p>
<span class="listmarker">2.</span> <b> 计算真实目标总数 </b>：真实标注中为 1 的像素数 = 5 个
</p>


</li>
<li>


<p>
<span class="listmarker">3.</span> <b> 计算预测目标总数 </b>：预测结果中为 1 的像素数 = 4 个
</p>


</li>
<li>


<p>
<span class="listmarker">4.</span> <b> 计算 Dice 系数 </b>：\(\frac {2 \times 3}{5 + 4} = \frac {6}{9} \approx 0.67\)
</p>


</li>
<li>


<p>
<span class="listmarker">5.</span> <b> 计算 Dice 损失 </b>：\(1 - 0.67 = 0.33\)
</p>
</li>
</ul>

</div>

</div>

<p>
<b> 为什么 Dice 损失适合类别不平衡？</b>
</p>

<p>
这是 Dice 损失最重要的特性。让我们看一个极端不平衡的例子：
</p>



<div
      class="tcolorbox"
      style=" border: 1px solid #404040; background: #F2F2F2; "
>



<div
      class="tcolorboxtitle"
      style=" border-top: 1px solid #404040; border-bottom: 1px solid #404040; background: #404040; color: #FFFFFF; "
>

<p>
<b> 类别不平衡示例 </b>
</p>
</div>



<div
      class="tcolorboxupper"
      style=" color: #000000; "
>

<p>
假设在一个 100×100 的图像中：
</p>
<ul class="itemize" style="list-style-type:none">


<li>
<p>
<span class="listmarker">‧</span> 目标区域：只有 50 个像素（占总数的 0.5
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> 背景区域：9950 个像素（占总数的 99.5
</p>
</li>
</ul>

<p>
如果模型做出一个” 懒惰” 的预测，将所有像素都标记为背景：
</p>
<ul class="itemize" style="list-style-type:none">


<li>
<p>
<span class="listmarker">‧</span> <b> 交叉熵损失 </b>：可能很小，因为 99.5
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b>Dice 损失 </b>：会很大（接近 1），因为目标区域完全被遗漏
</p>
</li>
</ul>

<p>
<b> 关键洞察：</b> Dice 损失专注于重叠区域，而不会被大量的背景像素” 稀释”。
</p>
</div>

</div>

<p>
<b>Dice 损失 vs 交叉熵损失：</b>
</p>

<figure id="autoid-13" class="table ">
<div class="center">
<table>

<tr style="display:none"><th>.</th></tr>


<tr class="hline">
<td class="tdl tvertbarl tvertbarr" style="border-left: 1px solid black; border-right: 1px solid black"><b> 特性 </b></td>
<td class="tdp tvertbarr" style="border-right: 1px solid black">

<p>
<b> 交叉熵损失 </b>
</p>
</td>
<td class="tdp tvertbarr" style="border-right: 1px solid black">

<p>
<b>Dice 损失 </b>
</p>
</td>
</tr>


<tr class="hline">
<td class="tdl tvertbarl tvertbarr" style="border-left: 1px solid black; border-right: 1px solid black"> 关注重点 </td>
<td class="tdp tvertbarr" style="border-right: 1px solid black">

<p>
每个像素的预测准确性
</p>
</td>
<td class="tdp tvertbarr" style="border-right: 1px solid black">

<p>
整体重叠程度
</p>
</td>
</tr>


<tr class="hline">
<td class="tdl tvertbarl tvertbarr" style="border-left: 1px solid black; border-right: 1px solid black"> 类别不平衡 </td>
<td class="tdp tvertbarr" style="border-right: 1px solid black">

<p>
可能被多数类主导
</p>
</td>
<td class="tdp tvertbarr" style="border-right: 1px solid black">

<p>
鲁棒性强
</p>
</td>
</tr>


<tr class="hline">
<td class="tdl tvertbarl tvertbarr" style="border-left: 1px solid black; border-right: 1px solid black"> 梯度特性 </td>
<td class="tdp tvertbarr" style="border-right: 1px solid black">

<p>
平滑，易于优化
</p>
</td>
<td class="tdp tvertbarr" style="border-right: 1px solid black">

<p>
非凸，可能有局部最优
</p>
</td>
</tr>


<tr class="hline">
<td class="tdl tvertbarl tvertbarr" style="border-left: 1px solid black; border-right: 1px solid black"> 边界精度 </td>
<td class="tdp tvertbarr" style="border-right: 1px solid black">

<p>
一般
</p>
</td>
<td class="tdp tvertbarr" style="border-right: 1px solid black">

<p>
优秀
</p>
</td>
</tr>


<tr class="hline">
<td class="tdl tvertbarl tvertbarr" style="border-left: 1px solid black; border-right: 1px solid black"> 收敛速度 </td>
<td class="tdp tvertbarr" style="border-right: 1px solid black">

<p>
通常较快
</p>
</td>
<td class="tdp tvertbarr" style="border-right: 1px solid black">

<p>
可能较慢
</p>
</td>
</tr>


<tr class="hline">
<td class="tdl tvertbarl tvertbarr" style="border-left: 1px solid black; border-right: 1px solid black"> 数值稳定性 </td>
<td class="tdp tvertbarr" style="border-right: 1px solid black">

<p>
需要处理 log(0)
</p>
</td>
<td class="tdp tvertbarr" style="border-right: 1px solid black">

<p>
需要处理分母为 0
</p>
</td>
</tr>


<tr class="hline" aria-hidden="true">
<td class="tdl"></td>
<td class="tdp">

</td>
<td class="tdp">

</td>
</tr>
</table>

</div>

</figure>

<p>
<b> 实际应用中的技巧：</b>
</p>

<ul class="enumerate" style="list-style-type:none">


<li>
<p>
<span class="listmarker">1.</span> <b> 平滑处理 </b>：为了避免分母为 0（当没有任何预测或真实目标时），我们添加一个小的平滑常数：
</p>
<p>
\[\mathcal {L}_{Dice} = 1 - \frac {2\sum _{i,j} y_{i,j} \cdot \hat {y}_{i,j} + \epsilon }{\sum _{i,j} y_{i,j} + \sum _{i,j} \hat {y}_{i,j} + \epsilon }\]
</p>
<p>
其中\(\epsilon \) 通常设为 1 或更小。
</p>
</li>
<li>


<p>
<span class="listmarker">2.</span> <b> 多类别扩展 </b>：对于多类别分割，通常计算每个类别的 Dice 损失，然后取平均：
</p>
<p>
\[\mathcal {L}_{MultiDice} = \frac {1}{C} \sum _{c=1}^{C} \mathcal {L}_{Dice}^{(c)}\]
</p>
</li>
<li>


<p>
<span class="listmarker">3.</span> <b> 组合使用 </b>：在实际应用中，经常将 Dice 损失与交叉熵损失结合使用以获得更好的性能
</p>
</li>
</ul>

<p>
<b> 医疗图像分割中的成功案例：</b>
</p>

<p>
Dice 损失在以下医疗图像分割任务中表现出色：
</p>
<ul class="itemize" style="list-style-type:none">


<li>
<p>
<span class="listmarker">‧</span> <b> 肿瘤检测：</b> 肿瘤通常只占图像很小一部分
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 血管分割：</b> 血管结构细长且稀疏
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 细胞计数：</b> 细胞小且密集，背景区域大
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 病灶定位：</b> 病灶可能只是几个像素大小
</p>
</li>
</ul>
<!--
...... subsubsection 组合损失策略......
-->
<h6 id="autosec-38"><span class="sectionnumber">3.4.3&#x2003;</span>组合损失策略</h6>
<a id="document-autopage-38"></a>



<p>
实际应用中，通常组合多种损失函数：
</p>

<p>
\[\mathcal {L}_{combined} = \alpha \cdot \mathcal {L}_{CE} + \beta \cdot \mathcal {L}_{Dice}\]
</p>

<p>
<b> 组合策略的优势：</b>
</p>
<ul class="itemize" style="list-style-type:none">


<li>
<p>
<span class="listmarker">‧</span> <b> 稳定性 + 精确性：</b> 交叉熵提供稳定的梯度，Dice 损失确保精确的分割边界。
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 训练平衡：</b> 避免单一损失的极端行为，提高训练稳定性。
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 性能提升：</b> 在多数医学图像分割任务中，组合损失优于单一损失。
</p>
</li>
</ul>

<p>
<b> 权重选择：</b>
</p>
<ul class="itemize" style="list-style-type:none">


<li>
<p>
<span class="listmarker">‧</span> <b> 平衡权重：</b> \(\alpha = \beta = 1\)，等权重组合
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 强调 Dice：</b> \(\alpha = 0.5, \beta = 1.0\)，更关注重叠度
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 动态调整：</b> 根据训练进度动态调整权重比例
</p>
</li>
</ul>
<!--
...... section U-Net 的训练策略......
-->
<h4 id="autosec-39"><span class="sectionnumber">4&#x2003;</span>U‑Net 的训练策略</h4>
<a id="document-autopage-39"></a>
<!--
...... subsection 数据增强技术......
-->
<h5 id="autosec-40"><span class="sectionnumber">4.1&#x2003;</span>数据增强技术</h5>
<a id="document-autopage-40"></a>



<p>
由于生物医学图像数据有限，U‑Net 大量使用数据增强技术来扩充训练集，提高模型的泛化能力。
</p>

<figure id="autoid-14" class="figure ">
<div class="center">



<div class="figurecaption">


图&nbsp;12: 弹性变形数据增强：展示原始图像和变形后的对比，模拟生物组织形变

</div>

<a id="fig:elastic_deform"></a>

</div>

</figure>

<figure id="autoid-15" class="figure ">
<div class="center">



<div class="figurecaption">


图&nbsp;13: 几何变换增强：包括随机旋转、缩放、翻转等操作

</div>

<a id="fig:geometric_aug"></a>

</div>

</figure>



<div
      class="tcolorbox"
      style=" border: 1px solid #404040; background: #F2F2F2; "
>



<div
      class="tcolorboxtitle"
      style=" border-top: 1px solid #404040; border-bottom: 1px solid #404040; background: #404040; color: #FFFFFF; "
>

<p>
<b> 常用数据增强方法 </b>
</p>
</div>



<div
      class="tcolorboxupper"
      style=" color: #000000; "
>

<ul class="itemize" style="list-style-type:none">


<li>
<p>
<span class="listmarker">‧</span> <b> 弹性变形：</b> 模拟生物组织的形变特性
</p>
<p>
<b> 实现原理：</b> 弹性变形通过生成位移场来实现：
</p>
<ul class="enumerate" style="list-style-type:none">


<li>
<p>
<span class="listmarker">1.</span> 生成随机位移场：\(\Delta (x,y) = (u(x,y), v(x,y))\)
</p>


</li>
<li>


<p>
<span class="listmarker">2.</span> 应用高斯滤波平滑：\(\Delta &apos; = G_{\sigma } * \Delta \)
</p>


</li>
<li>


<p>
<span class="listmarker">3.</span> 对图像进行变形：\(I_{augmented}(x,y) = I(x+\alpha u(x,y), y+\alpha v(x,y))\)
</p>
</li>
</ul>
<p>
其中\(\alpha \) 控制变形强度，\(\sigma \) 控制变形的平滑程度。这种变换特别适合医学图像，因为它能够模拟器官的自然形变。
</p>
</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 随机旋转：</b> 提高旋转不变性
</p>
<p>
<b> 角度选择：</b> 通常选择\([-15°, 15°]\) 范围内的随机角度，避免过度旋转导致医学图像的不合理。对于某些特定的医学图像（如肺部 CT），可能需要限制旋转角度以保持解剖结构的合理性。
</p>
</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 尺度变换：</b> 适应不同大小的目标
</p>
<p>
<b> 缩放策略：</b> 缩放因子通常在\([0.8, 1.2]\) 范围内，过大的缩放可能导致图像失真。在医学图像中，缩放需要考虑成像设备的物理约束。
</p>
</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 亮度调整：</b> 增强对光照变化的鲁棒性
</p>
<p>
<b> 医学图像特殊性：</b> 医学图像的亮度调整需要考虑成像设备的特性：
</p>
<ul class="itemize" style="list-style-type:none">


<li>
<p>
<span class="listmarker">–</span> <b>CT 图像：</b> 调整窗宽窗位，模拟不同扫描参数
</p>


</li>
<li>


<p>
<span class="listmarker">–</span> <b>MRI 图像：</b> 调整对比度，模拟不同磁场强度
</p>


</li>
<li>


<p>
<span class="listmarker">–</span> <b>X 光图像：</b> 调整曝光度，模拟不同拍摄条件
</p>
</li>
</ul>
</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 随机裁剪：</b> 增加训练样本多样性
</p>
<p>
<b> 裁剪策略：</b> 对于大型医学图像，随机裁剪可以生成多个训练样本。裁剪尺寸通常选择为 2 的幂次方（如 256×256, 512×512），以配合 U‑Net 的下采样操作。
</p>
</li>
</ul>

</div>

</div>
<!--
...... subsection 优化器选择......
-->
<h5 id="autosec-43"><span class="sectionnumber">4.2&#x2003;</span>优化器选择</h5>
<a id="document-autopage-43"></a>
<!--
...... subsubsection Adam 优化器......
-->
<h6 id="autosec-44"><span class="sectionnumber">4.2.1&#x2003;</span>Adam 优化器</h6>
<a id="document-autopage-44"></a>



<p>
U‑Net 通常使用 Adam 优化器，结合了动量和自适应学习率：
</p>
<ul class="itemize" style="list-style-type:none">


<li>
<p>
<span class="listmarker">‧</span> <b> 自适应学习率：</b> 根据梯度历史动态调整学习率
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 动量机制：</b> 加速收敛，减少震荡
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 偏差修正：</b> 修正初期估计的偏差
</p>
</li>
</ul>
<!--
...... subsubsection 学习率调度......
-->
<h6 id="autosec-45"><span class="sectionnumber">4.2.2&#x2003;</span>学习率调度</h6>
<a id="document-autopage-45"></a>



<p>
常用的学习率调度策略包括：
</p>
<ul class="itemize" style="list-style-type:none">


<li>
<p>
<span class="listmarker">‧</span> <b> 余弦退火：</b> 学习率按余弦函数衰减
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 步长衰减：</b> 固定间隔降低学习率
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 热重启：</b> 周期性重置学习率
</p>
</li>
</ul>
<!--
...... section U-Net 的应用领域......
-->
<h4 id="autosec-46"><span class="sectionnumber">5&#x2003;</span>U‑Net 的应用领域</h4>
<a id="document-autopage-46"></a>
<!--
...... subsection 生物医学图像分割......
-->
<h5 id="autosec-47"><span class="sectionnumber">5.1&#x2003;</span>生物医学图像分割</h5>
<a id="document-autopage-47"></a>



<figure id="autoid-16" class="figure ">
<div class="center">



<div class="figurecaption">


图&nbsp;14: U‑Net 在细胞分割中的应用：展示原始图像、真实标注和分割结果的对比

</div>

<a id="fig:cell_segmentation"></a>

</div>

</figure>
<!--
...... subsubsection 细胞分割......
-->
<h6 id="autosec-49"><span class="sectionnumber">5.1.1&#x2003;</span>细胞分割</h6>
<a id="document-autopage-49"></a>



<p>
U‑Net 在细胞分割任务中表现卓越：
</p>
<ul class="itemize" style="list-style-type:none">


<li>
<p>
<span class="listmarker">‧</span> <b> 精确边界：</b> 能够准确识别细胞边界
</p>
<p>
<b> 技术细节：</b> 细胞边界通常只有 1‑2 个像素宽，且对比度低。U‑Net 通过跳跃连接将浅层的边缘信息传递给深层，使得最终输出能够保留精细的边界细节。
</p>
</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 密度处理：</b> 有效处理密集细胞区域
</p>
<p>
<b> 挑战与解决：</b> 密集细胞区域中，细胞之间可能相互接触或重叠，导致边界模糊。U‑Net 的多尺度特征融合能力使其能够同时利用局部纹理特征和全局形状信息来区分相邻细胞。
</p>
</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 形态保持：</b> 保留细胞的形态特征
</p>
<p>
<b> 形态学意义：</b> 细胞的形状、大小和形态学特征对疾病诊断很重要。U‑Net 通过保持空间精度，确保分割结果能够反映细胞的真实形态。
</p>
</li>
</ul>
<!--
...... subsubsection 器官分割......
-->
<h6 id="autosec-50"><span class="sectionnumber">5.1.2&#x2003;</span>器官分割</h6>
<a id="document-autopage-50"></a>



<p>
在医学影像中分割各种器官：
</p>
<ul class="itemize" style="list-style-type:none">


<li>
<p>
<span class="listmarker">‧</span> <b> 肝脏分割：</b> CT 图像中的肝脏自动分割
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 肺部检测：</b> 胸部 X 光中的肺部区域识别
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 脑部区域：</b> MRI 图像中的脑组织分割
</p>
</li>
</ul>
<!--
...... subsubsection 病灶检测......
-->
<h6 id="autosec-51"><span class="sectionnumber">5.1.3&#x2003;</span>病灶检测</h6>
<a id="document-autopage-51"></a>



<p>
识别和分割医学图像中的病灶：
</p>
<ul class="itemize" style="list-style-type:none">


<li>
<p>
<span class="listmarker">‧</span> <b> 肿瘤检测：</b> 癌症的早期筛查和诊断
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 血管分析：</b> 血管疾病的检测和量化
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 骨折识别：</b> X 光图像中的骨折线检测
</p>
</li>
</ul>
<!--
...... subsection 工业检测......
-->
<h5 id="autosec-52"><span class="sectionnumber">5.2&#x2003;</span>工业检测</h5>
<a id="document-autopage-52"></a>
<!--
...... subsubsection 缺陷检测......
-->
<h6 id="autosec-53"><span class="sectionnumber">5.2.1&#x2003;</span>缺陷检测</h6>
<a id="document-autopage-53"></a>



<p>
在制造业中检测产品缺陷：
</p>
<ul class="itemize" style="list-style-type:none">


<li>
<p>
<span class="listmarker">‧</span> <b> 表面缺陷：</b> 检测产品表面的划痕、凹陷等
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 内部缺陷：</b> X 光检测内部结构缺陷
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 装配错误：</b> 检测组件装配错误
</p>
</li>
</ul>
<!--
...... subsection 遥感图像分析......
-->
<h5 id="autosec-54"><span class="sectionnumber">5.3&#x2003;</span>遥感图像分析</h5>
<a id="document-autopage-54"></a>
<!--
...... subsubsection 土地利用分类......
-->
<h6 id="autosec-55"><span class="sectionnumber">5.3.1&#x2003;</span>土地利用分类</h6>
<a id="document-autopage-55"></a>



<p>
从卫星图像中分割不同土地利用类型：
</p>
<ul class="itemize" style="list-style-type:none">


<li>
<p>
<span class="listmarker">‧</span> <b> 建筑区域：</b> 识别城市建筑区域
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 植被覆盖：</b> 分割森林和农田区域
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 水体检测：</b> 识别河流、湖泊等水体
</p>
</li>
</ul>
<!--
...... subsubsection 灾害监测......
-->
<h6 id="autosec-56"><span class="sectionnumber">5.3.2&#x2003;</span>灾害监测</h6>
<a id="document-autopage-56"></a>



<p>
监测自然灾害影响区域：
</p>
<ul class="itemize" style="list-style-type:none">


<li>
<p>
<span class="listmarker">‧</span> <b> 火灾范围：</b> 森林火灾影响的区域分割
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 洪水淹没：</b> 洪水淹没区域的精确识别
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 地震破坏：</b> 建筑物破坏程度评估
</p>
</li>
</ul>
<!--
...... section U-Net 的改进变体......
-->
<h4 id="autosec-57"><span class="sectionnumber">6&#x2003;</span>U‑Net 的改进变体</h4>
<a id="document-autopage-57"></a>
<!--
...... subsection U-Net++：嵌套密集连接......
-->
<h5 id="autosec-58"><span class="sectionnumber">6.1&#x2003;</span>U‑Net++：嵌套密集连接</h5>
<a id="document-autopage-58"></a>



<p>
U‑Net++ 通过引入嵌套的密集连接改进了原始 U‑Net：
</p>



<div
      class="tcolorbox"
      style=" border: 1px solid #404040; background: #F2F2F2; "
>



<div
      class="tcolorboxtitle"
      style=" border-top: 1px solid #404040; border-bottom: 1px solid #404040; background: #404040; color: #FFFFFF; "
>

<p>
<b>U‑Net++ 的改进 </b>
</p>
</div>



<div
      class="tcolorboxupper"
      style=" color: #000000; "
>

<ul class="itemize" style="list-style-type:none">


<li>
<p>
<span class="listmarker">‧</span> <b> 密集连接：</b> 编码器和解码器之间的密集连接
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 深度监督：</b> 多个分割输出，提供额外的监督信号
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 剪枝能力：</b> 可以剪枝为不同深度的网络
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 特征复用：</b> 更好的特征复用和梯度流动
</p>
</li>
</ul>

</div>

</div>
<!--
...... subsection Attention U-Net：注意力机制......
-->
<h5 id="autosec-59"><span class="sectionnumber">6.2&#x2003;</span>Attention U‑Net：注意力机制</h5>
<a id="document-autopage-59"></a>



<p>
Attention U‑Net 引入注意力机制来自适应地调整特征权重：
</p>



<div
      class="tcolorbox"
      style=" border: 1px solid #404040; background: #F2F2F2; "
>



<div
      class="tcolorboxtitle"
      style=" border-top: 1px solid #404040; border-bottom: 1px solid #404040; background: #404040; color: #FFFFFF; "
>

<p>
<b> 注意力机制的贡献 </b>
</p>
</div>



<div
      class="tcolorboxupper"
      style=" color: #000000; "
>

<ul class="itemize" style="list-style-type:none">


<li>
<p>
<span class="listmarker">‧</span> <b> 自适应权重：</b> 自动学习关注重要区域
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 噪声抑制：</b> 抑制不相关区域的特征
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 可解释性：</b> 提供决策的可视化解释
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 性能提升：</b> 在复杂场景中提高分割精度
</p>
</li>
</ul>

</div>

</div>
<!--
...... subsection U-Net 3+：全尺度跳跃连接......
-->
<h5 id="autosec-60"><span class="sectionnumber">6.3&#x2003;</span>U‑Net 3+：全尺度跳跃连接</h5>
<a id="document-autopage-60"></a>



<p>
U‑Net 3+ 通过全尺度的跳跃连接进一步改进架构：
</p>



<div
      class="tcolorbox"
      style=" border: 1px solid #404040; background: #F2F2F2; "
>



<div
      class="tcolorboxtitle"
      style=" border-top: 1px solid #404040; border-bottom: 1px solid #404040; background: #404040; color: #FFFFFF; "
>

<p>
<b>U‑Net 3+ 的创新 </b>
</p>
</div>



<div
      class="tcolorboxupper"
      style=" color: #000000; "
>

<ul class="itemize" style="list-style-type:none">


<li>
<p>
<span class="listmarker">‧</span> <b> 全尺度特征：</b> 编码器和解码器之间的全尺度连接
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 深度监督：</b> 多层次的监督机制
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 级联上采样：</b> 逐步上采样融合多尺度特征
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 混合损失：</b> 结合多种损失函数
</p>
</li>
</ul>

</div>

</div>
<!--
...... subsection ResUNet：残差连接......
-->
<h5 id="autosec-61"><span class="sectionnumber">6.4&#x2003;</span>ResUNet：残差连接</h5>
<a id="document-autopage-61"></a>



<p>
ResUNet 将残差网络的思想融入 U‑Net 架构：
</p>



<div
      class="tcolorbox"
      style=" border: 1px solid #404040; background: #F2F2F2; "
>



<div
      class="tcolorboxtitle"
      style=" border-top: 1px solid #404040; border-bottom: 1px solid #404040; background: #404040; color: #FFFFFF; "
>

<p>
<b> 残差连接的优势 </b>
</p>
</div>



<div
      class="tcolorboxupper"
      style=" color: #000000; "
>

<ul class="itemize" style="list-style-type:none">


<li>
<p>
<span class="listmarker">‧</span> <b> 深层网络：</b> 支持更深的网络结构
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 梯度流动：</b> 改善深层网络的梯度流动
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 训练稳定性：</b> 提高训练过程的稳定性
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 特征学习：</b> 更好地学习复杂特征表示
</p>
</li>
</ul>

</div>

</div>
<!--
...... section U-Net 的实现细节......
-->
<h4 id="autosec-62"><span class="sectionnumber">7&#x2003;</span>U‑Net 的实现细节</h4>
<a id="document-autopage-62"></a>
<!--
...... subsection 网络配置参数......
-->
<h5 id="autosec-63"><span class="sectionnumber">7.1&#x2003;</span>网络配置参数</h5>
<a id="document-autopage-63"></a>
<!--
...... subsubsection 基础参数设置......
-->
<h6 id="autosec-64"><span class="sectionnumber">7.1.1&#x2003;</span>基础参数设置</h6>
<a id="document-autopage-64"></a>



<ul class="itemize" style="list-style-type:none">


<li>
<p>
<span class="listmarker">‧</span> <b> 输入尺寸：</b> 通常为\(512 \times 512\) 或\(256 \times 256\)
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 初始通道数：</b> 通常为 64，可根据任务调整
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 网络深度：</b> 4‑5 个下采样层级
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 卷积核大小：</b> 主要使用\(3 \times 3\) 卷积
</p>
</li>
</ul>
<!--
...... subsubsection 训练参数......
-->
<h6 id="autosec-65"><span class="sectionnumber">7.1.2&#x2003;</span>训练参数</h6>
<a id="document-autopage-65"></a>



<ul class="itemize" style="list-style-type:none">


<li>
<p>
<span class="listmarker">‧</span> <b> 批次大小：</b> 根据 GPU 内存调整，通常为 2‑16
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 学习率：</b> 初始学习率通常为\(10^{-4}\) 到\(10^{-3}\)
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 训练轮数：</b> 100‑500 轮，使用早停策略
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 优化器：</b> Adam 或 SGD with momentum
</p>
</li>
</ul>
<!--
...... subsection 硬件需求分析......
-->
<h5 id="autosec-66"><span class="sectionnumber">7.2&#x2003;</span>硬件需求分析</h5>
<a id="document-autopage-66"></a>
<!--
...... subsubsection GPU 要求......
-->
<h6 id="autosec-67"><span class="sectionnumber">7.2.1&#x2003;</span>GPU 要求</h6>
<a id="document-autopage-67"></a>



<p>
U‑Net 对 GPU 内存的需求主要取决于：
</p>
<ul class="itemize" style="list-style-type:none">


<li>
<p>
<span class="listmarker">‧</span> <b> 输入分辨率：</b> 更高分辨率需要更多内存
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 批次大小：</b> 增大批次需要线性增加内存
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 网络深度：</b> 更深网络需要更多内存
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 特征通道数：</b> 通道数增加显著影响内存使用
</p>
</li>
</ul>
<!--
...... subsubsection 内存优化策略......
-->
<h6 id="autosec-68"><span class="sectionnumber">7.2.2&#x2003;</span>内存优化策略</h6>
<a id="document-autopage-68"></a>



<ul class="itemize" style="list-style-type:none">


<li>
<p>
<span class="listmarker">‧</span> <b> 混合精度训练：</b> 使用 FP16 减少内存占用
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 梯度累积：</b> 模拟大批次训练
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 检查点技术：</b> 以计算换内存
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 数据并行：</b> 多 GPU 分布式训练
</p>
</li>
</ul>
<!--
...... section 评估指标与性能分析......
-->
<h4 id="autosec-69"><span class="sectionnumber">8&#x2003;</span>评估指标与性能分析</h4>
<a id="document-autopage-69"></a>



<figure id="autoid-17" class="figure ">
<div class="center">



<div class="figurecaption">


图&nbsp;15: U‑Net 训练曲线：展示损失函数、Dice 系数和 IoU 指标随训练轮数的变化

</div>

<a id="fig:training_curves"></a>

</div>

</figure>
<!--
...... subsection 分割质量评估......
-->
<h5 id="autosec-71"><span class="sectionnumber">8.1&#x2003;</span>分割质量评估</h5>
<a id="document-autopage-71"></a>
<!--
...... subsubsection 像素级指标......
-->
<h6 id="autosec-72"><span class="sectionnumber">8.1.1&#x2003;</span>像素级指标</h6>
<a id="document-autopage-72"></a>



<ul class="itemize" style="list-style-type:none">


<li>
<p>
<span class="listmarker">‧</span> <b> 像素准确率（Pixel Accuracy）：</b>
</p>
<p>
\[PA = \frac {TP + TN}{TP + TN + FP + FN}\]
</p>
</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 平均交并比（Mean IoU）：</b>
</p>
<p>
\[mIoU = \frac {1}{C} \sum _{c=1}^{C} \frac {TP_c}{TP_c + FP_c + FN_c}\]
</p>
</li>
<li>


<p>
<span class="listmarker">‧</span> <b>Dice 系数：</b>
</p>
<p>
\[Dice = \frac {2TP}{2TP + FP + FN}\]
</p>
<p>


</p>
</li>
</ul>
<!--
...... subsubsection 边界质量指标......
-->
<h6 id="autosec-73"><span class="sectionnumber">8.1.2&#x2003;</span>边界质量指标</h6>
<a id="document-autopage-73"></a>



<ul class="itemize" style="list-style-type:none">


<li>
<p>
<span class="listmarker">‧</span> <b>Hausdorff 距离：</b> 衡量边界形状相似性
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 平均表面距离：</b> 计算表面间的平均距离
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span>
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 边界 F1 分数：</b> 基于边界的 F1 度量
</p>
</li>
</ul>
<!--
...... subsection 推理性能分析......
-->
<h5 id="autosec-74"><span class="sectionnumber">8.2&#x2003;</span>推理性能分析</h5>
<a id="document-autopage-74"></a>
<!--
...... subsubsection 计算复杂度......
-->
<h6 id="autosec-75"><span class="sectionnumber">8.2.1&#x2003;</span>计算复杂度</h6>
<a id="document-autopage-75"></a>



<p>
U‑Net 的计算复杂度主要由以下因素决定：
</p>
<ul class="itemize" style="list-style-type:none">


<li>
<p>
<span class="listmarker">‧</span> <b> 浮点运算次数：</b> 约为\(O(n^2 \cdot c^2 \cdot k^2)\)
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 内存访问模式：</b> 卷积操作的内存访问效率
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 并行度：</b> 卷积操作的并行执行能力
</p>
</li>
</ul>
<!--
...... subsubsection 推理速度优化......
-->
<h6 id="autosec-76"><span class="sectionnumber">8.2.2&#x2003;</span>推理速度优化</h6>
<a id="document-autopage-76"></a>



<ul class="itemize" style="list-style-type:none">


<li>
<p>
<span class="listmarker">‧</span> <b> 模型量化：</b> 使用 INT8 量化加速推理
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 模型剪枝：</b> 移除冗余连接和参数
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 知识蒸馏：</b> 使用轻量模型学习重模型知识
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 硬件加速：</b> 利用专用 AI 加速器
</p>
</li>
</ul>
<!--
...... section 实践案例与代码实现......
-->
<h4 id="autosec-77"><span class="sectionnumber">9&#x2003;</span>实践案例与代码实现</h4>
<a id="document-autopage-77"></a>
<!--
...... subsection PyTorch 实现示例......
-->
<h5 id="autosec-78"><span class="sectionnumber">9.1&#x2003;</span>PyTorch 实现示例</h5>
<a id="document-autopage-78"></a>



<figure id="autoid-18" class="figure ">
<div class="center">



<div class="figurecaption">


图&nbsp;16: 交互式分割界面：展示用户如何通过点击和修正来获得精确的分割结果

</div>

<a id="fig:interactive_gui"></a>

</div>

</figure>

<p>
以下是一个简化的 U‑Net PyTorch 实现：
</p>



<div
      class="tcolorbox"
      style=" border: 1px solid #404040; background: #F2F2F2; "
>



<div
      class="tcolorboxtitle"
      style=" border-top: 1px solid #404040; border-bottom: 1px solid #404040; background: #404040; color: #FFFFFF; "
>

<p>
<b> 双卷积块 </b>
</p>
</div>



<div
      class="tcolorboxupper"
      style=" color: #000000; "
>
<pre class="verbatim">
class DoubleConv(nn.Module):
      def __init__(self, in_channels, out_channels):
         super().__init__()
         self.double_conv = nn.Sequential(
              nn.Conv2d(in_channels, out_channels, 3, padding=1),
              nn.BatchNorm2d(out_channels),
              nn.ReLU(inplace=True),
              nn.Conv2d(out_channels, out_channels, 3, padding=1),
              nn.BatchNorm2d(out_channels),
              nn.ReLU(inplace=True)
         )


      def forward(self, x):
         return self.double_conv(x)


</pre>

</div>

</div>



<div
      class="tcolorbox"
      style=" border: 1px solid #404040; background: #F2F2F2; "
>



<div
      class="tcolorboxtitle"
      style=" border-top: 1px solid #404040; border-bottom: 1px solid #404040; background: #404040; color: #FFFFFF; "
>

<p>
<b> 下采样和上采样 </b>
</p>
</div>



<div
      class="tcolorboxupper"
      style=" color: #000000; "
>
<pre class="verbatim">
class Down(nn.Module):
   def __init__(self, in_channels, out_channels):
         super().__init__()
         self.maxpool_conv = nn.Sequential(
             nn.MaxPool2d(2),
             DoubleConv(in_channels, out_channels)
         )


   def forward(self, x):
         return self.maxpool_conv(x)


class Up(nn.Module):
   def __init__(self, in_channels, out_channels):
         super().__init__()
         self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, 2, stride=2)
         self.conv = DoubleConv(in_channels, out_channels)


   def forward(self, x1, x2):
         x1 = self.up(x1)
         diffY = x2.size()[2] - x1.size()[2]
         diffX = x2.size()[3] - x1.size()[3]
         x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,
                            diffY // 2, diffY - diffY // 2])
         x = torch.cat([x2, x1], dim=1)
         return self.conv(x)


</pre>

</div>

</div>
<!--
...... subsection 训练配置示例......
-->
<h5 id="autosec-82"><span class="sectionnumber">9.2&#x2003;</span>训练配置示例</h5>
<a id="document-autopage-82"></a>




<div
      class="tcolorbox"
      style=" border: 1px solid #404040; background: #F2F2F2; "
>



<div
      class="tcolorboxtitle"
      style=" border-top: 1px solid #404040; border-bottom: 1px solid #404040; background: #404040; color: #FFFFFF; "
>

<p>
<b> 训练循环框架 </b>
</p>
</div>



<div
      class="tcolorboxupper"
      style=" color: #000000; "
>
<pre class="verbatim">
def train_unet(model, train_loader, val_loader, num_epochs):
   criterion = nn.CrossEntropyLoss()
   optimizer = optim.Adam(model.parameters(), lr=1e-4)
   scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)


   for epoch in range(num_epochs):
         model.train()
         train_loss = 0.0


         for batch_idx, (images, masks) in enumerate(train_loader):
             images, masks = images.to(device), masks.to(device)


             optimizer.zero_grad()
             outputs = model(images)
             loss = criterion(outputs, masks)
             loss.backward()
             optimizer.step()


             train_loss += loss.item()


         # 验证阶段
         val_loss, val_iou = validate(model, val_loader, criterion)
         scheduler.step()


         print(f'Epoch {epoch}: Train Loss: {train_loss:.4f}, '
               f'Val Loss: {val_loss:.4f}, Val IoU: {val_iou:.4f}')


</pre>

</div>

</div>
<!--
...... section 常见问题与解决方案......
-->
<h4 id="autosec-84"><span class="sectionnumber">10&#x2003;</span>常见问题与解决方案</h4>
<a id="document-autopage-84"></a>
<!--
...... subsection 训练相关问题......
-->
<h5 id="autosec-85"><span class="sectionnumber">10.1&#x2003;</span>训练相关问题</h5>
<a id="document-autopage-85"></a>
<!--
...... subsubsection 梯度消失/爆炸......
-->
<h6 id="autosec-86"><span class="sectionnumber">10.1.1&#x2003;</span>梯度消失/爆炸</h6>
<a id="document-autopage-86"></a>




<div
      class="tcolorbox"
      style=" border: 1px solid #404040; background: #F2F2F2; "
>



<div
      class="tcolorboxtitle"
      style=" border-top: 1px solid #404040; border-bottom: 1px solid #404040; background: #404040; color: #FFFFFF; "
>

<p>
<b> 解决方案 </b>
</p>
</div>



<div
      class="tcolorboxupper"
      style=" color: #000000; "
>

<ul class="itemize" style="list-style-type:none">


<li>
<p>
<span class="listmarker">‧</span> <b> 批归一化：</b> 添加 BN 层稳定训练
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 残差连接：</b> 使用 ResNet 风格的残差块
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 梯度裁剪：</b> 限制梯度大小防止爆炸
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b>Xavier 初始化：</b> 合理的权重初始化
</p>
</li>
</ul>

</div>

</div>
<!--
...... subsubsection 过拟合问题......
-->
<h6 id="autosec-87"><span class="sectionnumber">10.1.2&#x2003;</span>过拟合问题</h6>
<a id="document-autopage-87"></a>




<div
      class="tcolorbox"
      style=" border: 1px solid #404040; background: #F2F2F2; "
>



<div
      class="tcolorboxtitle"
      style=" border-top: 1px solid #404040; border-bottom: 1px solid #404040; background: #404040; color: #FFFFFF; "
>

<p>
<b> 缓解策略 </b>
</p>
</div>



<div
      class="tcolorboxupper"
      style=" color: #000000; "
>

<ul class="itemize" style="list-style-type:none">


<li>
<p>
<span class="listmarker">‧</span> <b> 数据增强：</b> 增加训练数据多样性
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b>Dropout：</b> 随机丢弃部分神经元
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 权重衰减：</b> L2 正则化防止过拟合
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 早停策略：</b> 验证性能不再提升时停止训练
</p>
</li>
</ul>

</div>

</div>
<!--
...... subsection 推理相关问题......
-->
<h5 id="autosec-88"><span class="sectionnumber">10.2&#x2003;</span>推理相关问题</h5>
<a id="document-autopage-88"></a>
<!--
...... subsubsection 内存不足......
-->
<h6 id="autosec-89"><span class="sectionnumber">10.2.1&#x2003;</span>内存不足</h6>
<a id="document-autopage-89"></a>




<div
      class="tcolorbox"
      style=" border: 1px solid #404040; background: #F2F2F2; "
>



<div
      class="tcolorboxtitle"
      style=" border-top: 1px solid #404040; border-bottom: 1px solid #404040; background: #404040; color: #FFFFFF; "
>

<p>
<b> 优化方法 </b>
</p>
</div>



<div
      class="tcolorboxupper"
      style=" color: #000000; "
>

<ul class="itemize" style="list-style-type:none">


<li>
<p>
<span class="listmarker">‧</span> <b> 图像分割：</b> 将大图像分割为小块处理
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 混合精度：</b> 使用半精度浮点数
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 梯度检查点：</b> 以计算换内存
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 模型并行：</b> 将模型分布到多个设备
</p>
</li>
</ul>

</div>

</div>
<!--
...... section 未来发展方向......
-->
<h4 id="autosec-90"><span class="sectionnumber">11&#x2003;</span>未来发展方向</h4>
<a id="document-autopage-90"></a>
<!--
...... subsection 架构创新趋势......
-->
<h5 id="autosec-91"><span class="sectionnumber">11.1&#x2003;</span>架构创新趋势</h5>
<a id="document-autopage-91"></a>
<!--
...... subsubsection Transformer 集成......
-->
<h6 id="autosec-92"><span class="sectionnumber">11.1.1&#x2003;</span>Transformer 集成</h6>
<a id="document-autopage-92"></a>



<p>
将 Vision Transformer 与 U‑Net 结合：
</p>
<ul class="itemize" style="list-style-type:none">


<li>
<p>
<span class="listmarker">‧</span> <b> 全局注意力：</b> 捕获长距离依赖关系
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 多头注意力：</b> 多角度理解图像内容
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 位置编码：</b> 保持空间位置信息
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 自监督学习：</b> 利用无标签数据预训练
</p>
</li>
</ul>
<!--
...... subsubsection 轻量化设计......
-->
<h6 id="autosec-93"><span class="sectionnumber">11.1.2&#x2003;</span>轻量化设计</h6>
<a id="document-autopage-93"></a>



<p>
针对移动端和嵌入式设备：
</p>
<ul class="itemize" style="list-style-type:none">


<li>
<p>
<span class="listmarker">‧</span> <b> 深度可分离卷积：</b> 减少计算复杂度
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 网络剪枝：</b> 移除冗余连接
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 神经架构搜索：</b> 自动寻找最优架构
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 知识蒸馏：</b> 大模型向小模型传授知识
</p>
</li>
</ul>
<!--
...... subsection 应用领域拓展......
-->
<h5 id="autosec-94"><span class="sectionnumber">11.2&#x2003;</span>应用领域拓展</h5>
<a id="document-autopage-94"></a>
<!--
...... subsubsection 3D 和时序分割......
-->
<h6 id="autosec-95"><span class="sectionnumber">11.2.1&#x2003;</span>3D 和时序分割</h6>
<a id="document-autopage-95"></a>



<p>
扩展到三维和时间维度：
</p>
<ul class="itemize" style="list-style-type:none">


<li>
<p>
<span class="listmarker">‧</span> <b>3D U‑Net：</b> 处理体积医学数据
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b>Video U‑Net：</b> 视频分割任务
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 时空注意力：</b> 同时建模空间和时间关系
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 多模态融合：</b> 结合多种成像模态
</p>
</li>
</ul>
<!--
...... subsubsection 交互式分割......
-->
<h6 id="autosec-96"><span class="sectionnumber">11.2.2&#x2003;</span>交互式分割</h6>
<a id="document-autopage-96"></a>



<p>
支持人机协作的分割系统：
</p>
<ul class="itemize" style="list-style-type:none">


<li>
<p>
<span class="listmarker">‧</span> <b> 少样本学习：</b> 用少量标注实现分割
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 主动学习：</b> 智能选择需要标注的样本
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 增量学习：</b> 逐步学习新的类别
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 用户反馈：</b> 根据用户修正优化结果
</p>
</li>
</ul>
<!--
...... section 总结......
-->
<h4 id="autosec-97"><span class="sectionnumber">12&#x2003;</span>总结</h4>
<a id="document-autopage-97"></a>



<p>
U‑Net 作为一种革命性的图像分割架构，其成功源于精巧的设计和对任务本质的深刻理解。通过编码器‑解码器结构和跳跃连接的创新设计，U‑Net 成功解决了图像分割中的核心挑战：如何在保持空间精度的同时获取语义信息。
</p>
<!--
...... subsection 核心贡献回顾......
-->
<h5 id="autosec-98"><span class="sectionnumber">12.1&#x2003;</span>核心贡献回顾</h5>
<a id="document-autopage-98"></a>



<p>
U‑Net 的主要贡献可以总结为：
</p>
<ul class="enumerate" style="list-style-type:none">


<li>
<p>
<span class="listmarker">1.</span> <b> 架构创新：</b> 首次提出完整的编码器‑解码器分割架构
</p>


</li>
<li>


<p>
<span class="listmarker">2.</span> <b> 跳跃连接：</b> 有效解决了细节保留和语义理解的双重需求
</p>


</li>
<li>


<p>
<span class="listmarker">3.</span> <b> 数据增强：</b> 针对医学图像特点设计了专门的数据增强策略
</p>


</li>
<li>


<p>
<span class="listmarker">4.</span> <b> 端到端学习：</b> 实现了从原始像素到分割结果的端到端优化
</p>
</li>
</ul>
<!--
...... subsection 设计哲学的启示......
-->
<h5 id="autosec-99"><span class="sectionnumber">12.2&#x2003;</span>设计哲学的启示</h5>
<a id="document-autopage-99"></a>



<p>
U‑Net 的成功为我们提供了宝贵的架构设计启示：
</p>
<ul class="enumerate" style="list-style-type:none">


<li>
<p>
<span class="listmarker">1.</span> <b> 问题导向：</b> 针对具体任务需求设计网络结构
</p>


</li>
<li>


<p>
<span class="listmarker">2.</span> <b> 多尺度融合：</b> 同时利用局部和全局信息
</p>


</li>
<li>


<p>
<span class="listmarker">3.</span> <b> 信息流动：</b> 确保网络各层间的有效信息传递
</p>


</li>
<li>


<p>
<span class="listmarker">4.</span> <b> 实用性优先：</b> 注重实际应用中的性能和效率
</p>
</li>
</ul>
<!--
...... subsection 持续演进的 U-Net 家族......
-->
<h5 id="autosec-100"><span class="sectionnumber">12.3&#x2003;</span>持续演进的 U‑Net 家族</h5>
<a id="document-autopage-100"></a>



<p>
U‑Net 架构仍在不断演进，新的变体层出不穷：
</p>
<ul class="itemize" style="list-style-type:none">


<li>
<p>
<span class="listmarker">‧</span> <b> 注意力机制：</b> 提高对重要区域的关注
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 密集连接：</b> 改善特征复用和梯度流动
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b> 多尺度融合：</b> 更精细的多尺度信息整合
</p>


</li>
<li>


<p>
<span class="listmarker">‧</span> <b>Transformer 融合：</b> 结合全局建模能力
</p>
</li>
</ul>

<p>
U‑Net 不仅在生物医学图像分割领域取得了巨大成功，其设计思想也深刻影响了整个计算机视觉领域。作为深度学习发展史上的里程碑，U‑Net 将继续为图像分割和相关任务的发展提供重要参考和启发。
</p>
<!--
...... section 参考文献......
-->
<h4 id="autosec-101">参考文献</h4>
<a id="document-autopage-101"></a>



<ul class="list" style="list-style-type:none">


<li>
<p>
<span class="listmarker">[1]&#x2003;</span> Ronneberger, O., Fischer, P., &amp; Brox, T. (2015). U‑net: Convolutional networks for biomedical image segmentation. In Medical Image Computing and
Computer‑Assisted Intervention–MICCAI 2015 (pp. 234‑241).
</p>
</li>
<li>


<p>
<span class="listmarker">[2]&#x2003;</span> Zhou, Z., Siddiquee, M. M. R., Tajbakhsh, N., &amp; Liang, J. (2018). Unet++: A nested u‑net architecture for medical image segmentation. In Deep Learning in
Medical Image Analysis and Multimodal Learning for Clinical Decision Support (pp. 3‑11).
</p>
</li>
<li>


<p>
<span class="listmarker">[3]&#x2003;</span> Oktay, O., Schlemper, J., Folgoc, L. L., Lee, M., Heinrich, M., Misawa, K., ... &amp; Rueckert, D. (2018). Attention u‑net: Learning where to look for the pancreas. arXiv
preprint arXiv:1804.03999.
</p>
</li>
<li>


<p>
<span class="listmarker">[4]&#x2003;</span> Huang, H., Lin, L., Tong, R., Hu, H., Zhang, Q., Iwamoto, Y., ... &amp; Zhang, L. (2020). UNet 3+: A full‑scale connected unet for medical image segmentation. In
ICASSP 2020‑2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) (pp. 1055‑1059).
</p>
</li>
<li>


<p>
<span class="listmarker">[5]&#x2003;</span> Zhang, Z., Liu, Q., &amp; Wang, Y. (2018). Road extraction by deep residual u‑net. IEEE Geoscience and Remote Sensing Letters, 15(5), 749‑753.
</p>
</li>
</ul>

<a id="document-autofile-last"></a>
</section>

</main>

</div>

</body>
</html>

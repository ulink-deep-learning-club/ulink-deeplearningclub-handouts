# 引言

在本教程中，我们将使用MNIST手写数字识别作为案例研究，通过这个经典任务来深入理解神经网络的核心组件。我们将首先介绍全连接层（Fully Connected Layer）的基本原理，然后逐步深入到卷积神经网络（CNN）层的学习。这些基础组件将在后续章节中详细展开，为构建更复杂的深度学习模型奠定基础。

## 构建成功神经网络的目标

构建一个成功的神经网络需要实现以下核心目标：

1. **表达能力（Expressiveness）**：神经网络的核心目标是构建一个灵活的计算架构，而非硬编码的规则或算法。与传统算法需要人工设计每条决策规则不同，神经网络通过其内部结构（包括层数、神经元数量和连接方式）来自动学习如何表示和转换数据。

   - **架构 vs 规则**：我们不是在编写"如果输入是X，则输出Y"的规则，而是在设计一个通用的计算模板，让网络通过训练数据主动发现最优的转换方式。
   - **层数的作用**：增加隐藏层的深度使网络能够学习数据的多层次表示——从低级特征（如图像中的边缘）到高级抽象概念（如物体识别）。每一层都作为前一层的"信息处理站"，逐步提炼和组织数据。
   - **宽度的影响**：扩展每层的神经元数量增加了该层可以捕捉的特征维度。更多的神经元提供更多的"计算单元"来同时学习不同的模式。
   - **灵活性和泛化能力**：通过调整网络的深度和宽度，我们可以创建一个足够灵活的架构来学习复杂的非线性关系，同时避免过度特化于特定规则。

2. **模式识别（Pattern Capture）**：网络应能够自动发现数据中的有意义的特征和规律，而无需手工设计特征。通过反向传播算法学习最优的权重和偏置，网络能够逐步改进其模式识别能力。

3. **泛化性能（Generalization）**：模型不仅要在训练数据上表现良好，更重要的是能够对未见过的新数据做出准确预测。这需要在模型复杂度和训练数据规模之间找到平衡。

4. **计算效率（Computational Efficiency）**：在保证性能的前提下，我们希望模型具有较少的参数和较低的计算成本，以便在实际应用中快速推理。

5. **稳定性和可靠性（Stability and Reliability）**：网络的训练过程应该稳定收敛，预测结果应该可靠且一致。

在接下来的章节中，我们将通过MNIST任务来演示如何在这些目标之间进行权衡，并逐步构建更高效的神经网络架构。


## MNIST数据集简介

MNIST（Modified National Institute of Standards and Technology）数据集是机器学习领域最经典的数据集之一，由Yann LeCun等人创建。该数据集包含：

- 训练集：60,000张手写数字图像
- 测试集：10,000张手写数字图像
- 图像尺寸：28×28像素，灰度图像
- 类别：0-9共10个数字类别

```{figure} ../../_static/images/mnist.png
:width: 80%
:align: center

MNIST图像数据集
```

MNIST数据集之所以成为 “Hello World” 级别的基准测试，是因为：

1. **规模适中**：足够大以展示机器学习的效果，又足够小以便快速实验
2. **预处理完善**：图像已经过标准化处理，可直接用于训练
3. **评估标准明确**：分类准确率的计算简单直观
4. **历史意义**：见证了从传统机器学习到深度学习的发展历程

## LeNet的历史意义

LeNet由Yann LeCun在1989年提出[^lecun1989backpropagation]，是最早的卷积神经网络之一。其历史意义在于：

- **开创性**：首次将卷积操作引入神经网络
- **实用性**：成功应用于银行支票的手写数字识别
- **理论基础**：奠定了现代CNN架构的基础
- **持久影响**：其设计思想至今仍在使用

```{admonition} LeNet的关键创新
:class: note

- **局部感受野**：通过卷积核捕捉局部特征
- **权值共享**：大幅减少参数数量
- **下采样**：通过池化层减少空间维度
- **端到端训练**：直接从原始像素学习特征表示
```

[^lecun1989backpropagation]: Y. LeCun, B. Boser, J. S. Denker, D. Henderson, R. E. Howard, W. Hubbard, and L. D. Jackel, "Backpropagation applied to handwritten zip code recognition," *Neural Computation*, vol. 1, no. 4, pp. 541–551, Winter 1989.
